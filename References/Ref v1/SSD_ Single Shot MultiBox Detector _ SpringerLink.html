<!DOCTYPE html>
<!-- saved from url=(0068)https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#citeas -->
<html lang="en" class="js" data-darkreader-mode="dynamic" data-darkreader-scheme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="darkreader darkreader--fallback" media="screen"></style><style class="darkreader darkreader--text" media="screen"></style><style class="darkreader darkreader--invert" media="screen">.jfk-bubble.gtx-bubble, .captcheck_answer_label > input + img, span#closed_text > img[src^="https://www.gstatic.com/images/branding/googlelogo"], span[data-href^="https://www.hcaptcha.com/"] > #icon, #bit-notification-bar-iframe, ::-webkit-calendar-picker-indicator {
    filter: invert(100%) hue-rotate(180deg) contrast(90%) !important;
}</style><style class="darkreader darkreader--inline" media="screen">[data-darkreader-inline-bgcolor] {
  background-color: var(--darkreader-inline-bgcolor) !important;
}
[data-darkreader-inline-bgimage] {
  background-image: var(--darkreader-inline-bgimage) !important;
}
[data-darkreader-inline-border] {
  border-color: var(--darkreader-inline-border) !important;
}
[data-darkreader-inline-border-bottom] {
  border-bottom-color: var(--darkreader-inline-border-bottom) !important;
}
[data-darkreader-inline-border-left] {
  border-left-color: var(--darkreader-inline-border-left) !important;
}
[data-darkreader-inline-border-right] {
  border-right-color: var(--darkreader-inline-border-right) !important;
}
[data-darkreader-inline-border-top] {
  border-top-color: var(--darkreader-inline-border-top) !important;
}
[data-darkreader-inline-boxshadow] {
  box-shadow: var(--darkreader-inline-boxshadow) !important;
}
[data-darkreader-inline-color] {
  color: var(--darkreader-inline-color) !important;
}
[data-darkreader-inline-fill] {
  fill: var(--darkreader-inline-fill) !important;
}
[data-darkreader-inline-stroke] {
  stroke: var(--darkreader-inline-stroke) !important;
}
[data-darkreader-inline-outline] {
  outline-color: var(--darkreader-inline-outline) !important;
}
[data-darkreader-inline-stopcolor] {
  stop-color: var(--darkreader-inline-stopcolor) !important;
}</style><style class="darkreader darkreader--variables" media="screen">:root {
   --darkreader-neutral-background: #131516;
   --darkreader-neutral-text: #d8d4cf;
   --darkreader-selection-background: #004daa;
   --darkreader-selection-text: #e8e6e3;
}</style><style class="darkreader darkreader--root-vars" media="screen"></style><style class="darkreader darkreader--user-agent" media="screen">html {
    background-color: #181a1b !important;
}
html {
    color-scheme: dark !important;
}
html, body {
    background-color: #181a1b;
}
html, body {
    border-color: #736b5e;
    color: #e8e6e3;
}
a {
    color: #3391ff;
}
table {
    border-color: #545b5e;
}
::placeholder {
    color: #b2aba1;
}
input:-webkit-autofill,
textarea:-webkit-autofill,
select:-webkit-autofill {
    background-color: #404400 !important;
    color: #e8e6e3 !important;
}
::-webkit-scrollbar {
    background-color: #202324;
    color: #aba499;
}
::-webkit-scrollbar-thumb {
    background-color: #454a4d;
}
::-webkit-scrollbar-thumb:hover {
    background-color: #575e62;
}
::-webkit-scrollbar-thumb:active {
    background-color: #484e51;
}
::-webkit-scrollbar-corner {
    background-color: #181a1b;
}
::selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}
::-moz-selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}</style>
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="applicable-device" content="pc,mobile">
    <meta name="access" content="Yes">

    
    
    <meta name="twitter:site" content="SpringerLink">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image:alt" content="Content cover image">
    <meta name="twitter:title" content="SSD: Single Shot MultiBox Detector">
    <meta name="twitter:description" content="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction...">
    <meta name="twitter:image" content="https://static-content.springer.com/cover/book/978-3-319-46448-0.jpg">
    <meta name="dc.identifier" content="10.1007/978-3-319-46448-0_2">
    <meta name="DOI" content="10.1007/978-3-319-46448-0_2">
    <meta name="dc.description" content="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction...">
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/978-3-319-46448-0_2.pdf">
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">
    <meta name="citation_abstract_html_url" content="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">
    <meta name="citation_inbook_title" content="Computer Vision – ECCV 2016">
    <meta name="citation_title" content="SSD: Single Shot MultiBox Detector">
    <meta name="citation_publication_date" content="2016">
    <meta name="citation_firstpage" content="21">
    <meta name="citation_lastpage" content="37">
    <meta name="citation_language" content="en">
    <meta name="citation_doi" content="10.1007/978-3-319-46448-0_2">
    <meta name="citation_conference_series_id" content="springer/eccv, dblp/eccv">
    <meta name="citation_conference_title" content="European Conference on Computer Vision">
    <meta name="citation_conference_abbrev" content="ECCV">
    <meta name="size" content="186157">
    <meta name="description" content="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction...">
    <meta name="citation_author" content="Liu, Wei">
    <meta name="citation_author_email" content="wliu@cs.unc.edu">
    <meta name="citation_author_institution" content="UNC Chapel Hill">
    <meta name="citation_author" content="Anguelov, Dragomir">
    <meta name="citation_author_email" content="drago@zoox.com">
    <meta name="citation_author_institution" content="Zoox Inc.">
    <meta name="citation_author" content="Erhan, Dumitru">
    <meta name="citation_author_email" content="dumitru@google.com">
    <meta name="citation_author_institution" content="Google Inc.">
    <meta name="citation_author" content="Szegedy, Christian">
    <meta name="citation_author_email" content="szegedy@google.com">
    <meta name="citation_author_institution" content="Google Inc.">
    <meta name="citation_author" content="Reed, Scott">
    <meta name="citation_author_email" content="reedscot@umich.edu">
    <meta name="citation_author_institution" content="University of Michigan">
    <meta name="citation_author" content="Fu, Cheng-Yang">
    <meta name="citation_author_email" content="cyfu@cs.unc.edu">
    <meta name="citation_author_institution" content="UNC Chapel Hill">
    <meta name="citation_author" content="Berg, Alexander C.">
    <meta name="citation_author_email" content="aberg@cs.unc.edu">
    <meta name="citation_author_institution" content="UNC Chapel Hill">
    <meta name="citation_publisher" content="Springer, Cham">
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1007/978-3-319-46448-0_2&amp;api_key=">
    <meta name="format-detection" content="telephone=no">
    

    
    
    <meta property="og:url" content="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">
    <meta property="og:type" content="Paper">
    <meta property="og:site_name" content="SpringerLink">
    <meta property="og:title" content="SSD: Single Shot MultiBox Detector">
    <meta property="og:description" content="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction...">
    <meta property="og:image" content="https://static-content.springer.com/cover/book/978-3-319-46448-0.jpg">
    


    <title>SSD: Single Shot MultiBox Detector | SpringerLink</title>

    <link rel="shortcut icon" href="https://link.springer.com/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico">
<link rel="icon" sizes="16x16 32x32 48x48" href="https://link.springer.com/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico">
<link rel="icon" sizes="16x16" type="image/png" href="https://link.springer.com/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png">
<link rel="icon" sizes="32x32" type="image/png" href="https://link.springer.com/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png">
<link rel="icon" sizes="48x48" type="image/png" href="https://link.springer.com/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png">
<link rel="apple-touch-icon" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png">
<link rel="apple-touch-icon" sizes="72x72" href="https://link.springer.com/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png">
<link rel="apple-touch-icon" sizes="76x76" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png">
<link rel="apple-touch-icon" sizes="114x114" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png">
<link rel="apple-touch-icon" sizes="120x120" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png">
<link rel="apple-touch-icon" sizes="144x144" href="https://link.springer.com/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png">
<link rel="apple-touch-icon" sizes="152x152" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://link.springer.com/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png">


    
    <script async="" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/MathJax.js.download"></script><script async="" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/gtm.js.download"></script><script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/consent-bundle-17-30.js.download" onload="initGTM(window,document,&#39;script&#39;,&#39;dataLayer&#39;,&#39;GTM-MRVXSHQ&#39;)"></script>

    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { html{text-size-adjust:100%;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:100%;height:100%;line-height:1.61803;overflow-y:scroll}body,img{max-width:100%}body{background:#fcfcfc;font-size:1.125rem;line-height:1.5;min-height:100%}main{display:block}h1{font-family:Georgia,Palatino,serif;font-size:2.25rem;font-style:normal;font-weight:400;line-height:1.4}a{background-color:transparent;color:#004b83;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}sup{font-size:75%;line-height:0;position:relative;top:-.5em;vertical-align:baseline}img{border:0;height:auto;vertical-align:middle}button,input{font-family:inherit;font-size:100%}input{line-height:1.15}button,input{overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:inherit}*{margin:0}h2{font-family:Georgia,Palatino,serif;font-size:1.75rem;font-style:normal;font-weight:400;line-height:1.4}label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}*{box-sizing:inherit}body,button,div,form,input,p{margin:0;padding:0}h1,h2{margin:0}h2+*{margin-block-start:1rem}h1+*{margin-block-start:3rem}[style*="display: none"]:first-child+*{margin-block-start:0}p{overflow-wrap:break-word;word-break:break-word}.c-app-header__theme{border-top-left-radius:2px;border-top-right-radius:2px;height:50px;margin:-16px -16px 0;overflow:hidden;position:relative}@media only screen and (min-width:1024px){.c-app-header__theme:after{background-color:hsla(0,0%,100%,.15);bottom:0;content:"";position:absolute;right:0;top:0;width:456px}}.c-app-header__content{padding-top:16px}@media only screen and (min-width:1024px){.c-app-header__content{display:flex}}.c-app-header__main{display:flex;flex:1 1 auto}.c-app-header__cover{margin-right:16px;margin-top:-50px;position:relative;z-index:5}.c-app-header__cover img{border:2px solid #fff;border-radius:4px;box-shadow:0 0 5px 2px hsla(0,0%,50%,.2);max-height:125px;max-width:96px}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--728x90 iframe{height:90px;max-width:970px}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad iframe{border:0;overflow:auto;vertical-align:top}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-breadcrumbs>li{display:inline}.c-skip-link{background:#f7fbfe;bottom:auto;color:#004b83;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#004b83}.c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;list-style:none;margin:0;padding:16px}@media only screen and (min-width:540px){.c-pagination{justify-content:center}}.c-pagination__item{margin-bottom:8px;margin-right:16px}.c-pagination__item:last-child{margin-right:0}.c-pagination__link{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;min-width:30px;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link svg,.c-pagination__link--disabled svg{fill:currentcolor}.c-pagination__link:visited{color:#004b83}.c-pagination__link:focus,.c-pagination__link:hover{border:1px solid #666;text-decoration:none}.c-pagination__link:focus,.c-pagination__link:hover{background-color:#666;background-image:none;color:#fff}.c-pagination__link:focus svg path,.c-pagination__link:hover svg path{fill:#fff}.c-pagination__link--disabled{align-items:center;background-color:transparent;background-image:none;border-radius:2px;color:#333;cursor:default;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;opacity:.67;padding:8px;position:relative;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link--disabled:visited{color:#333}.c-pagination__link--disabled,.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{border:1px solid #ccc;text-decoration:none}.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{background-color:transparent;background-image:none;color:#333}.c-pagination__link--disabled:focus svg path,.c-pagination__link--disabled:hover svg path{fill:#333}.c-pagination__link--active{background-color:#666;background-image:none;border-color:#666;color:#fff;cursor:default}.c-pagination__ellipsis{background:0 0;border:0;min-width:auto;padding-left:0;padding-right:0}.c-pagination__icon{fill:#999;height:12px;width:16px}.c-pagination__icon--active{fill:#004b83}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#666;height:10px;margin:4px 4px 0;width:10px}.c-box{background-color:#fff;border:1px solid #ccc;border-radius:2px;line-height:1.3;padding:16px}.c-box--shadowed{box-shadow:0 0 5px 0 hsla(0,0%,50%,.1)}.c-header{background-color:#fff;border-bottom:4px solid #00285a;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;padding:16px 0}.c-header__container,.c-header__menu{align-items:center;display:flex;flex-wrap:wrap}@supports (gap:2em){.c-header__container,.c-header__menu{gap:2em 2em}}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit}@supports not (gap:2em){.c-header__item{margin-left:24px}}.c-header__container{justify-content:space-between;margin:0 auto;max-width:1280px;padding:0 16px}@supports not (gap:2em){.c-header__brand{margin-right:32px}}.c-header__brand a{display:block;text-decoration:none}.c-header__link{color:inherit}.c-popup-search{background-color:#eee;box-shadow:0 3px 3px -3px rgba(0,0,0,.21);padding:16px 0;position:relative;z-index:10}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;top:100%;width:100%}.c-popup-search__container{margin:auto;max-width:70%}}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-main-column{font-family:Georgia,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;margin-top:0;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #f2f2f2;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-breadcrumbs--truncated .c-breadcrumbs__link{display:inline-block;max-width:45%;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom;white-space:nowrap}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__section-item .c-article-section__title-number{display:none}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff}.c-pdf-download__link .u-icon{padding-top:2px}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}.app-search__content{display:flex}.app-search__label{color:#666;display:inline-block;font-size:.875rem;margin-bottom:8px}.app-search__input{border:1px solid #b3b3b3;border-bottom-left-radius:3px;border-top-left-radius:3px;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.21);flex:0 1 auto;font-size:.875rem;line-height:1.2;padding:.75em 1em;vertical-align:middle;width:100%}.app-search__button{align-items:center;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);border-radius:0 2px 2px 0;color:#fff;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:50px}.app-search__button svg,.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);color:#fff}.u-button--full-width{display:flex;width:100%}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:flex;width:100%}.u-align-items-center{align-items:center}.u-justify-content-space-between{justify-content:space-between}.u-flex-shrink{flex:0 1 auto}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-mbs-0{margin-block-start:0!important}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-0{margin-top:0}.u-mr-24{margin-right:24px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-float-left{float:left}.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.u-text-sm{font-size:1rem}.u-text-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-h3{font-family:Georgia,Palatino,serif;font-size:1.5rem;font-style:normal;font-weight:400;line-height:1.4}.hide{display:none;visibility:hidden}.visually-hidden{clip:rect(1px,1px,1px,1px);height:1px;position:absolute!important;width:1px}.c-article-section__content p{line-height:1.8}.c-pagination__input{border:1px solid #bfbfbf;border-radius:2px;box-shadow:inset 0 2px 6px 0 rgba(51,51,51,.2);box-sizing:initial;display:inline-block;height:28px;margin:0;max-width:64px;min-width:16px;padding:0 8px;text-align:center;transition:width .15s ease 0s}.c-pagination__input::-webkit-inner-spin-button,.c-pagination__input::-webkit-outer-spin-button{-webkit-appearance:none;margin:0}.c-article-associated-content__container .c-article-associated-content__collection-label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.063rem}.c-article-associated-content__container .c-article-associated-content__collection-title{font-size:1.063rem;font-weight:400}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-section__title,.c-article-title{font-weight:400}.c-chapter-book-series{font-size:1rem}.c-chapter-identifiers{margin:16px 0 8px}.c-chapter-book-details{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative}.c-chapter-book-details__title{font-weight:700}.c-chapter-book-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-chapter-book-details a{color:inherit}@media only screen and (max-width:539px){.c-chapter-book-details__meta{display:block}}.c-header__cart-icon{margin-right:12px}.c-header__navigation{display:flex}.c-cover-image-lightbox{align-items:center;bottom:0;display:flex;justify-content:center;left:0;opacity:0;position:fixed;right:0;top:0;transition:all .15s ease-in 0s;visibility:hidden;z-index:-1}.js-cover-image-lightbox--close{background:0 0;border:0;color:#fff;cursor:pointer;font-size:1.875rem;padding:13px;position:absolute;right:10px;top:0}.c-cover-image-lightbox__image{max-height:90vh;width:auto}.c-expand-overlay{background:#fff;color:#333;opacity:.5;padding:2px;position:absolute;right:3px;top:3px} }</style><style class="darkreader darkreader--sync" media="screen"></style>
    <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/enhanced-article-e156672f9e.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" onload="this.media=&#39;only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)&#39;;this.onload=null"><style class="darkreader darkreader--sync" media="screen"></style>


    
    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/978-3-319-46448-0_2","Page":"chapter","page":{"attributes":{"environment":"live"}},"Country":"MT","japan":false,"doi":"10.1007-978-3-319-46448-0_2","Keywords":"Real-time object detection, Convolutional neural network","kwrd":["Real-time_object_detection","Convolutional_neural_network"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"permanently-free","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-978-3-319-46448-0","Full HTML":"Y","session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1611-3349","pissn":"0302-9743"},"book":{"doi":"10.1007/978-3-319-46448-0","title":"Computer Vision – ECCV 2016","pisbn":"978-3-319-46447-3","eisbn":"978-3-319-46448-0","bookProductType":"Proceedings","seriesTitle":"Lecture Notes in Computer Science","seriesId":"558"},"chapter":{"doi":"10.1007/978-3-319-46448-0_2"},"type":"ConferencePaper","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"SCI","secondarySubjects":{"1":"Image Processing and Computer Vision","2":"Pattern Recognition","3":"Artificial Intelligence","4":"Computer Graphics"},"secondarySubjectCodes":{"1":"SCI22021","2":"SCI2203X","3":"SCI21000","4":"SCI22013"}},"sucode":"SUCO11645"},"attributes":{"deliveryPlatform":"oscar"},"country":"MT","Has Preview":"N","subjectCodes":"SCI,SCI22021,SCI2203X,SCI21000,SCI22013","PMC":["SCI","SCI22021","SCI2203X","SCI21000","SCI22013"]},"Event Category":"Conference Paper","ConferenceSeriesId":"eccv, eccv","productId":"9783319464480"}];
    </script>

    <script>
    window.dataLayer.push({
        ga4MeasurementId: 'G-B3E4QL2TPR',
        ga360TrackingId: 'UA-26408784-1',
        twitterId: 'o47a7',
        ga4ServerUrl: 'https://collect.springer.com',
        imprint: 'springerlink'
    });
</script>

    <script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('springer.com') > -1) {
                e.src = 'https://cmp-static.springer.com/production_live/consent-bundle-17-30.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/lib/cookie-consent.min.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

    <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>

    
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>


    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-51eb718839.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-711ad3939e.js', 'async': false},
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/app-es5-bundle-c8d17b980a.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-1a36c45380.js', 'async': false, 'module': true}
                
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-f999617c9b.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-1051dda857.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/airbrake-es5-bundle-711ad3939e.js.download"></script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/polyfill-es5-bundle-51eb718839.js.download"></script>

    
    
    <link rel="canonical" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">
    

    
    <script type="application/ld+json">{"headline":"SSD: Single Shot MultiBox Detector","pageEnd":"37","pageStart":"21","image":"https://media.springernature.com/w153/springer-static/cover/book/978-3-319-46448-0.jpg","genre":["Computer Science","Computer Science (R0)"],"isPartOf":{"name":"Computer Vision – ECCV 2016","isbn":["978-3-319-46448-0","978-3-319-46447-3"],"@type":"Book"},"publisher":{"name":"Springer International Publishing","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Wei Liu","affiliation":[{"name":"UNC Chapel Hill","address":{"name":"UNC Chapel Hill, Chapel Hill, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"wliu@cs.unc.edu","@type":"Person"},{"name":"Dragomir Anguelov","affiliation":[{"name":"Zoox Inc.","address":{"name":"Zoox Inc., Palo Alto, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Dumitru Erhan","affiliation":[{"name":"Google Inc.","address":{"name":"Google Inc., Mountain View, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Christian Szegedy","affiliation":[{"name":"Google Inc.","address":{"name":"Google Inc., Mountain View, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Scott Reed","affiliation":[{"name":"University of Michigan","address":{"name":"University of Michigan, Ann-Arbor, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Cheng-Yang Fu","affiliation":[{"name":"UNC Chapel Hill","address":{"name":"UNC Chapel Hill, Chapel Hill, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Alexander C. Berg","affiliation":[{"name":"UNC Chapel Hill","address":{"name":"UNC Chapel Hill, Chapel Hill, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"keywords":"Real-time object detection, Convolutional neural network","description":"We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For \n                  \n                    \n                  \n                  $$300 \\times 300$$\n                  \n                      \n                    \n                 input, SSD achieves 74.3 % mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for \n                  \n                    \n                  \n                  $$512 \\times 512$$\n                  \n                      \n                    \n                 input, SSD achieves 76.9 % mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at \n                  https://github.com/weiliu89/caffe/tree/ssd\n                  \n                .","datePublished":"2016","isAccessibleForFree":true,"@type":"ScholarlyArticle","@context":"https://schema.org"}</script>

<meta name="darkreader" content="eca5b06de8274a96b7ede84f21407bab"><style class="darkreader darkreader--override" media="screen">.vimvixen-hint {
    background-color: #7b5300 !important;
    border-color: #d8b013 !important;
    color: #f3e8c8 !important;
}
::placeholder {
    opacity: 0.5 !important;
}
#edge-translate-panel-body,
.MuiTypography-body1,
.nfe-quote-text {
    color: var(--darkreader-neutral-text) !important;
}
gr-main-header {
    background-color: #0f3a48 !important;
}
.tou-z65h9k,
.tou-mignzq,
.tou-1b6i2ox,
.tou-lnqlqk {
    background-color: var(--darkreader-neutral-background) !important;
}
.tou-75mvi {
    background-color: #032029 !important;
}
.tou-ta9e87,
.tou-1w3fhi0,
.tou-1b8t2us,
.tou-py7lfi,
.tou-1lpmd9d,
.tou-1frrtv8,
.tou-17ezmgn {
    background-color: #0a0a0a !important;
}
.tou-uknfeu {
    background-color: #231603 !important;
}
.tou-6i3zyv {
    background-color: #19576c !important;
}</style><style type="text/css">.cc-banner{-webkit-box-sizing:border-box;box-sizing:border-box;background-color:#01324b;color:#fff;position:fixed;bottom:0;left:0;right:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif!important;line-height:1.5;z-index:99999}.cc-banner *{color:inherit!important}.cc-banner:focus{outline:none}.cc-banner a{color:#fff;text-decoration:underline}.cc-banner a:focus{outline:none;-webkit-box-shadow:0 0 0 3px #fece3e;box-shadow:0 0 0 3px #fece3e}.cc-banner a:active,.cc-banner a:focus,.cc-banner a:hover{text-decoration:none;color:inherit}.cc-banner__content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin:0 auto;max-width:1320px;max-height:90vh;padding:12px}@media (min-width:680px){.cc-banner__content{padding:16px}}@media (min-width:980px){.cc-banner__content{padding-top:60px;padding-bottom:60px}}.cc-banner__title{font-size:18px;margin:0 0 12px}@media (min-width:980px){.cc-banner__title{margin:0 0 16px;font-size:28px}}.cc-banner__body{-webkit-box-flex:1;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;overflow-x:hidden;overflow-y:auto;padding:0 0 16px}@media (min-width:680px){.cc-banner__body{padding:0;margin:0 0 16px}}.cc-banner__copy{font-size:14px;margin:0}@media (min-width:980px){.cc-banner__copy{font-size:16px}}.cc-banner__footer{padding:12px;margin:0 -12px -12px;background-color:#012132;border-top:1px solid rgba(0,0,0,.3);-webkit-box-shadow:0 0 5px 0 rgba(0,0,0,.8);box-shadow:0 0 5px 0 rgba(0,0,0,.8);position:relative}@media (min-width:380px){.cc-banner__footer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-align:center;-webkit-align-items:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between}}@media (min-width:680px){.cc-banner__footer{margin:0;padding:0;background-color:transparent;border-top:0;-webkit-box-shadow:none;box-shadow:none;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start}}.cc-banner__button{width:100%;white-space:nowrap}@media (min-width:380px){.cc-banner__button{width:auto}}@media (min-width:680px){.cc-banner__button{width:-webkit-fit-content;width:-moz-fit-content;width:fit-content}}.cc-banner__button:not(:last-child){margin-bottom:4px}@media (min-width:680px){.cc-banner__button:not(:last-child){margin-right:8px;margin-bottom:0}}@media (min-width:980px){.cc-banner__button:not(:last-child){margin-right:16px}}@media (min-width:380px){.cc-banner__button-accept,.cc-banner__button-reject{width:100%}}@media (min-width:380px) and (max-width:680px){.cc-banner__button-accept,.cc-banner__button-reject{width:100%}}@media (min-width:680px){.cc-banner__button-accept,.cc-banner__button-reject{width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;min-width:240px}}.cc-banner__button-preferences{padding-left:0;padding-right:0}@media (min-width:380px){.cc-banner__button-preferences{-webkit-box-flex:0;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin:auto}}@media (min-width:680px){.cc-banner__button-preferences{margin:0}}@media (min-width:380px) and (max-width:680px){.cc-banner__button-break{display:block}}.cc-button{font-size:13px;font-weight:700;padding:.5em 1em;color:#fff;border:1px solid #183642;background-color:#000;border-radius:3px;cursor:pointer;line-height:1.2}.cc-button:focus{outline:none;-webkit-box-shadow:0 0 0 3px #fece3e;box-shadow:0 0 0 3px #fece3e}.cc-button:hover{-webkit-box-shadow:0 -2px 4px 0 rgba(60,64,67,.15),0 2px 4px 0 rgba(60,64,67,.15);box-shadow:0 -2px 4px 0 rgba(60,64,67,.15),0 2px 4px 0 rgba(60,64,67,.15);text-decoration:underline}@media (min-width:680px){.cc-button{padding:.75em 1em;font-size:14px}}.cc-button--contrast{color:#000!important;border-color:#fff;background-color:#fff}.cc-button--outline{background-color:transparent;color:#000!important}.cc-button--contrast.cc-button--outline{color:#fff!important}.cc-button--link{color:inherit;text-decoration:underline;background-color:transparent;border-color:transparent}.cc-button--link:hover{text-decoration:none;-webkit-box-shadow:none;box-shadow:none}@media (max-width:380px){.cc-button__truncated{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.cc-radio{position:relative}.cc-radio *{cursor:pointer}.cc-radio__input{width:22px;height:22px;position:absolute;top:0;left:0}.cc-radio__input:focus{outline:none}.cc-radio__label{padding-left:30px;font-size:14px;line-height:22px;margin:0;color:inherit}.cc-radio__label:after,.cc-radio__label:before{position:absolute;content:"";display:block;background-color:#fff}.cc-radio__label:before{width:22px;height:22px;top:0;left:0;border:2px solid;border-radius:50%}.cc-radio__label:after{top:6px;left:6px;width:0;height:0;border:5px solid;border-radius:50%;opacity:0}.cc-radio__input:focus+.cc-radio__label:before{outline:none;-webkit-box-shadow:0 0 0 3px #fece3e;box-shadow:0 0 0 3px #fece3e}.cc-radio__label--hidden{display:none}.cc-radio__input:checked+.cc-radio__label:after{opacity:1}.cc-radio__input:disabled{cursor:default}.cc-radio__input:disabled+.cc-radio__label{opacity:.5;cursor:default}.cc-preferences{-webkit-box-sizing:border-box;box-sizing:border-box;color:#111;font-family:sans-serif;overflow:auto;z-index:100000;position:fixed;background-color:rgba(5,10,20,.95);line-height:1.4;top:0;left:0;right:0;bottom:0}.cc-preferences:focus{outline:none}.cc-preferences *,.cc-preferences :after,.cc-preferences :before{-webkit-box-sizing:inherit!important;box-sizing:inherit!important}.cc-preferences h1,.cc-preferences h2,.cc-preferences h3,.cc-preferences h4,.cc-preferences h5,.cc-preferences h6{font-family:sans-serif;font-style:normal}.cc-preferences a{color:inherit;text-decoration:underline}.cc-preferences a:hover{text-decoration:none;color:inherit}.cc-preferences input{margin:0}.cc-preferences__dialog{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:16px;margin:auto;max-width:960px;max-height:100vh}.cc-preferences__dialog>:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px}.cc-preferences__close{position:absolute;border-radius:3px;top:24px;right:24px;padding:0;width:40px;height:40px;border:0;font-size:40px;line-height:1;cursor:pointer;background:transparent;font-family:Times New Roman,serif}.cc-preferences__close:focus{outline:none;-webkit-box-shadow:0 0 0 3px #fece3e;box-shadow:0 0 0 3px #fece3e}.cc-preferences__close-label{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.cc-preferences__header{background:#fff;text-align:center;padding:16px;border-bottom:1px solid #d0d0d0;border-top-left-radius:5px;border-top-right-radius:5px}.cc-preferences__title{font-family:sans-serif;font-size:18px;font-weight:700;padding-right:24px;margin:0;color:#111}@media (min-width:480px){.cc-preferences__title{padding-right:0}}@media (min-width:980px){.cc-preferences__title{font-size:22px}}.cc-preferences__body{padding:16px;-webkit-box-flex:1;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;min-height:200px;overflow-x:hidden;overflow-y:auto;background:#fff}.cc-preferences__footer{background:#fff;margin-bottom:0;padding:16px;border-top:1px solid #d0d0d0;-webkit-box-shadow:0 0 5px 0 rgba(0,0,0,.2);box-shadow:0 0 5px 0 rgba(0,0,0,.2);position:relative}@media (min-width:480px){.cc-preferences__footer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-webkit-align-items:center;-ms-flex-align:center;align-items:center}}.cc-preferences__footer>.cc-button{display:block;width:100%}@media (min-width:480px){.cc-preferences__footer>.cc-button{-webkit-box-flex:1;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content}}@media (min-width:980px){.cc-preferences__footer>.cc-button{width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto}}@media (min-width:480px){.cc-preferences__footer>.cc-button:not(:first-child){margin-left:16px;margin-right:16px}}.cc-preferences__footer>.cc-button:not(:last-child){margin-bottom:8px}@media (min-width:480px){.cc-preferences__footer>.cc-button:not(:last-child){margin-bottom:0}}@media (min-width:980px){.cc-preferences__footer>.cc-button:last-child{margin-left:auto}}.cc-preferences__categories{list-style:none;padding:0;margin:0}.cc-preferences__category:not(:last-child){margin-bottom:16px;padding-bottom:16px;border-bottom:1px solid #ececec}.cc-preferences__category input{margin-right:10px}.cc-preferences__category-header{margin:0 0 8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-align:baseline;-webkit-align-items:baseline;-ms-flex-align:baseline;align-items:baseline}.cc-preferences__category-heading{margin:0;font-size:16px;font-weight:700;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-align:baseline;-webkit-align-items:baseline;-ms-flex-align:baseline;align-items:baseline}.cc-preferences__category-description{margin:0 0 8px;font-size:14px}.cc-preferences__category-footer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-align:baseline;-webkit-align-items:baseline;-ms-flex-align:baseline;align-items:baseline}.cc-preferences__status{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.cc-preferences__controls{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0}.cc-preferences__controls>:not(:last-child){margin-right:16px}.cc-preferences__always-on{font-size:14px;position:relative;padding-left:26px}.cc-preferences__always-on:before{content:"";display:block;position:absolute;left:0;top:2px;width:18px;height:10px;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);border:solid;border-width:0 0 4px 4px;border-top-color:transparent;background:transparent}.cc-preferences__details-button{position:relative;font-size:14px;padding:2px 4px;font-weight:400;border:1px solid transparent;background-color:#fff;color:#000}.cc-preferences__details-button--show{background-color:#000;border-color:#000;color:#fff}.cc-preferences__details-button--show:before{content:"";display:block;position:absolute;right:50%;top:100%;width:0;height:0;margin-right:-8px;border-left:8px solid transparent;border-right:8px solid transparent;border-top:8px solid #111}.cc-preferences__details{font-size:14px;display:none;padding:12px 0 0;border-top:2px solid #000;margin:12px 0 0}.cc-preferences__details--show{display:block}.cc-preferences__cookie-list,.cc-preferences__provider-list{list-style:none;margin:0;padding:0}.cc-preferences__provider-list{-webkit-columns:170px;-moz-columns:170px;columns:170px}.cc-preferences__cookie-title{font-size:1em;margin:0}.cc-preferences__cookie-description{font-size:1em;margin:0 0 8px}.cc-preferences__cookie-domain{color:#666;padding-left:4px;margin-left:8px;border-left:1px solid #999}body.cc-has-preferences-open{overflow:hidden;position:relative}</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none; box-sizing: content-box}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_test.mjx-test-display {display: table!important}
.MathJax_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_test.mjx-test-default {display: block!important; clear: both}
.MathJax_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.MathJax_em_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60em}
.mjx-test-inline .MathJax_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.5') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.5') format('opentype')}
#MathJax_Message {margin: 0}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style class="darkreader darkreader--sync" media="screen"></style><style type="text/css">@font-face {font-family: MathJax_AMS; src: url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.5') format('woff'), url('https://cdn.jsdelivr.net/npm/mathjax@2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.5') format('opentype')}
</style><style class="darkreader darkreader--sync" media="screen"></style></head>
<body class="shared-article-renderer"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; --darkreader-inline-border-top: initial; --darkreader-inline-border-right: initial; --darkreader-inline-border-bottom: initial; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left=""><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div><section class="cc-banner" data-cc-banner="" data-nosnippet="" aria-labelledby="cc-banner-label">
        <div class="cc-banner__content">
            <header class="cc-banner__header">
                <h2 class="cc-banner__title" id="cc-banner-label">Your Privacy</h2>
			</header>
            <div class="cc-banner__body">
                <p class="cc-banner__copy">
                    We use cookies to make sure that our website works properly, as well as some ‘optional’ cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on ‘Manage Settings’, where you can also find more information about how your personal data is processed.
                    Further information can be found in our <a href="https://link.springer.com/privacystatement">privacy policy</a>.
				</p>
            </div>
            <div class="cc-banner__footer">
                <button data-cc-action="accept" class="cc-button cc-button--contrast cc-banner__button cc-banner__button-accept">Accept all cookies</button>
                
                <button data-cc-action="preferences" class="cc-button cc-button--link cc-banner__button cc-banner__button-preferences">Manage preferences</button>
            </div>
		</div>
    </section>
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        <a class="c-skip-link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#main-content">Skip to main content</a>

        
            
            <div class="u-hide u-show-following-ad"></div>
            <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
                <div class="c-ad__inner">
                    <p class="c-ad__label">Advertisement</p>
                    <div id="div-gpt-ad-LB1" data-pa11y-ignore="" data-gpt="" data-test="LB1-ad" data-gpt-unitpath="/270604982/springerlink/book/chapter" data-gpt-sizes="728x90" style="min-width:728px;min-height:90px" data-gpt-targeting="pos=LB1;"></div>
                </div>
            </aside>


<div class="app-frontend-toolkit u-position-relative u-mbs-0">
        <header class="c-header u-mb-24" data-test="publisher-header">
    
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="https://link.springer.com/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset="/oscar-static/images/springerlink/svg/springerlink-6c9a864b59.svg">
            <img src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/springerlink-1db8a5b8b1.png" alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button" class="c-header__link u-button-reset u-mr-24" data-expander="" data-expander-target="#popup-search" data-expander-autofocus="firstTabbable" data-test="header-search-button" aria-haspopup="true" aria-expanded="false">
            <span class="u-display-flex u-align-items-center">
                <span>Search</span>
                <svg class="u-icon u-flex-static u-ml-8" aria-hidden="true" focusable="false">
                    <use xlink:href="#icon-search"></use>
                </svg>
            </span>
        </button>

        <div class="c-header__cart-icon">
            <div id="ecommerce-header-cart-icon-link" class="c-header__item ecommerce-cart" style="display:inline-block;margin-right:10px">
 <a class="c-header__link" href="https://order.springer.com/public/cart" style="appearance: none; border: none; background: none; color: inherit; position: relative; --darkreader-inline-border-top: initial; --darkreader-inline-border-right: initial; --darkreader-inline-border-bottom: initial; --darkreader-inline-border-left: initial; --darkreader-inline-bgimage: none; --darkreader-inline-bgcolor: initial; --darkreader-inline-color: inherit;" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left="" data-darkreader-inline-bgimage="" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">
  <svg aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg" style="vertical-align:text-bottom">
   <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z" fill="#333" data-darkreader-inline-fill="" style="--darkreader-inline-fill: #c8c3bc;"></path>
  </svg><span class="u-screenreader-only visually-hidden">Go to cart</span><span class="cart-info" style="display: none; position: absolute; top: -4px; right: -10px; background-color: rgb(196, 6, 6); color: rgb(255, 255, 255); width: 18px; height: 18px; font-size: 11px; border-radius: 50%; line-height: 17.5px; text-align: center; --darkreader-inline-bgcolor: #9d0505; --darkreader-inline-color: #e8e6e3;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color=""></span></a>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    console.log("listen to updatedCart event");
    document.body.addEventListener("updatedCart", function () {
        console.log("updatedCart happened");
        updateCartIcon().then(function () { return console.log("Cart state update upon event"); });
    }, false);
    return updateCartIcon().then(function () { return console.log("Initial cart state update"); });
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function () { return console.log("Could not fetch cart info"); });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
        </div>

        <nav class="u-position-relative">
            <ul class="c-header__menu">
                
        
            <li class="c-header__item">
                <a data-test="login-link" class="c-header__link" href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-46448-0_2" data-track="click" data-track-category="header" data-track-action="login header" data-track-label="link">Log in</a>
            </li>
        

        


            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        
            <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide" hidden="">
                <div class="c-popup-search__content">
                    <div class="u-container">
                        <div class="c-popup-search__container" data-test="springerlink-popup-search">
                            <div class="app-search">
    <form role="search" method="GET" action="https://link.springer.com/search">
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input="" autocomplete="off" name="query" type="text" value="" required="true">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" aria-hidden="true" focusable="false">
                    <use xlink:href="#icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                        </div>
                    </div>
                </div>
            </div>
        
    
</div>
        

        

<div class="u-container u-mb-32 u-clearfix" id="main-content" data-component="article-container">
    
    <div class="u-hide-at-lg js-context-bar-sticky-point-mobile">
        
    </div>
    

    <header class="u-mb-24" data-test="chapter-information-header">
        <div class="c-box c-box--shadowed"><div class="c-app-header"><div class="c-app-header__theme" style="background-image: url(&#39;//media.springernature.com/dominant-colour/springer-static/cover/book/978-3-319-46448-0.jpg&#39;)"></div><div class="c-app-header__content"><div class="c-app-header__main"><div class="c-app-header__cover"><div class="c-app-expand-overlay-wrapper"><a data-component="cover-zoom" data-img-src="//media.springernature.com/full/springer-static/cover-hires/book/978-3-319-46448-0" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/cover"><picture><source type="image/webp" srcset="                                                         //media.springernature.com/w92/springer-static/cover/book/978-3-319-46448-0.jpg?as=webp 1x,                                                         //media.springernature.com/w184/springer-static/cover/book/978-3-319-46448-0.jpg?as=webp 2x"><img src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/978-3-319-46448-0.jpg" width="90" height="130" alt="Book cover"></picture><svg data-component="expand-icon" class="c-expand-overlay u-icon" width="18" height="18" aria-hidden="true" focusable="false"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-expand-image"></use></svg></a></div></div><div class="c-cover-image-lightbox u-hide" data-component="cover-lightbox"><button type="button" aria-label="Close expanded book cover" data-component="close-cover-lightbox" class="js-cover-image-lightbox--close"><span aria-hidden="true">×</span></button><picture><source type="image/webp" srcset="//media.springernature.com/full/springer-static/cover-hires/book/978-3-319-46448-0?as=webp"><img class="c-cover-image-lightbox__image" alt="Book cover" height="1200" width="800" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/978-3-319-46448-0"></picture></div><div class="u-flex-shrink"><p class="c-chapter-info-details u-mb-8"><a data-track="click" data-track-action="open conference" data-track-label="link" href="https://link.springer.com/conference/eccv%20eccv">European Conference on Computer Vision</a></p><p class="c-chapter-book-details right-arrow">ECCV 2016: <a class="c-chapter-book-details__title" data-test="book-link" data-track="click" data-track-action="open book series" data-track-label="link" href="https://link.springer.com/book/10.1007/978-3-319-46448-0">Computer Vision – ECCV 2016</a>
                                        pp
                                         21–37<a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#citeas" class="c-chapter-book-details__cite-as u-hide-print" data-track="click" data-track-action="cite this chapter" data-track-label="link">Cite as</a></p></div></div></div></div></div>
    </header>

    
    
        <nav class="u-mb-16" aria-label="breadcrumbs" data-test="article-breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--truncated" itemscope="" itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="https://link.springer.com/" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="Conference paper" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)" data-darkreader-inline-fill="" style="--darkreader-inline-fill: #a8a095;"></path>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="https://link.springer.com/book/10.1007/978-3-319-46448-0" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="Conference paper" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">Computer Vision – ECCV 2016</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)" data-darkreader-inline-fill="" style="--darkreader-inline-fill: #a8a095;"></path>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Conference paper</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    


    <main class="c-article-main-column u-float-left js-main-column u-text-sans-serif" data-track-component="conference paper">
        
            
            <div class="c-context-bar c-context-bar--no-button u-hide" data-test="context-bar" data-context-bar="" aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        SSD: Single Shot MultiBox Detector
                    </div>
                    
                </div>
            </div>
        

        <article lang="en">
            <header data-test="chapter-detail-header">
                <div class="c-article-header">
                    <h1 class="c-article-title" data-test="chapter-title" data-chapter-title="">SSD: Single Shot MultiBox Detector</h1>
                    <ul class="c-article-author-list c-article-author-list--short js-no-scroll" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Wei-Liu" data-author-popup="auth-Wei-Liu" data-corresp-id="c1">Wei Liu<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-email"></use></svg></a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff17" tabindex="-1">17</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Dragomir-Anguelov" data-author-popup="auth-Dragomir-Anguelov">Dragomir Anguelov</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff18" tabindex="-1">18</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Dumitru-Erhan" data-author-popup="auth-Dumitru-Erhan">Dumitru Erhan</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff19" tabindex="-1">19</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Christian-Szegedy" data-author-popup="auth-Christian-Szegedy">Christian Szegedy</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff19" tabindex="-1">19</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Scott-Reed" data-author-popup="auth-Scott-Reed">Scott Reed</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff20" tabindex="-1">20</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Cheng_Yang-Fu" data-author-popup="auth-Cheng_Yang-Fu">Cheng-Yang Fu</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff17" tabindex="-1">17</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 7 authors for this article" title="Show all 7 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#auth-Alexander_C_-Berg" data-author-popup="auth-Alexander_C_-Berg">Alexander C. Berg</a><sup class="u-js-hide"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Aff17" tabindex="-1">17</a></sup>&nbsp;</li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-plus"></use></svg><span>Show authors</span></button>
                    <ul class="c-article-identifiers c-chapter-identifiers">
                        
    
        <li class="c-article-identifiers__item" data-test="article-category">Conference paper</li>
    
    

                        
    

                        <li class="c-article-identifiers__item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#chapter-info" data-track="click" data-track-action="publication date" data-track-label="link">First Online: <time datetime="2016-09-17">17 September 2016</time></a></li>
                    </ul>

                    <div data-test="article-metrics">
                        <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">180k <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">7196
                            <a href="http://citations.springer.com/item?doi=10.1007/978-3-319-46448-0_2" target="_blank" rel="noopener" title="Visit Springer Citations for full citation details" class="c-article-metrics-bar__label" data-track="click" data-track-action="Citation count" data-track-label="link">Citations</a></p>
                    </li>
                
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">119
                            
                                <a href="https://link.altmetric.com/details/4855030" target="_blank" rel="noopener" title="Visit Altmetric for full social mention details" class="c-article-metrics-bar__label" data-track="click" data-track-action="Social mentions" data-track-label="link">Altmetric</a></p>
                            
                    </li>
                
            
        </ul>
    </div>
</div>

                    </div>

                    
    
        <p class="c-chapter-book-series">Part of the <a data-track="click" data-track-action="open book series" data-track-label="link" href="https://link.springer.com/bookseries/558">Lecture Notes in Computer Science</a> book series (LNIP,volume 9905)</p>
    

                    
                </div>
            </header>

            <div data-article-body="true" class="c-article-body">

                
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 id="Abs1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mn" id="MathJax-Span-3" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-4" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-5" style="font-family: MathJax_Main; padding-left: 0.201em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-1">300 \times 300</script></span> input, SSD achieves 74.3&nbsp;% mAP on VOC2007 <span class="u-monospace">test</span> at 59&nbsp;FPS on a Nvidia Titan X and for <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-6" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-7"><span class="mn" id="MathJax-Span-8" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-9" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-10" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-2">512 \times 512</script></span> input, SSD achieves 76.9&nbsp;% mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at <a href="https://github.com/weiliu89/caffe/tree/ssd">https://github.com/weiliu89/caffe/tree/ssd</a>.</p><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span>Real-time object detection</span></li><li class="c-article-subject-list__subject"><span>Convolutional neural network</span></li></ul></div></div></section>
                

                

                

                
                <div data-test="chapter-cobranding-and-download">
                    
    <div class="note test-pdf-link" id="cobranding-and-download-availability-text">
        
            <div class="c-article-access-provider" data-component="provided-by-box">
                
                
                    <p class="c-article-access-provider__text">
                        <a href="https://link.springer.com/content/pdf/10.1007/978-3-319-46448-0_2.pdf?pdf=inline%20link" class="c-pdf-download__link" style="display: inline; padding:0px!important;" target="_blank" rel="noopener" data-track="click" data-track-action="Pdf download" data-track-label="inline link" download="">Download</a> conference paper PDF
                    </p>
                
            </div>
        
    </div>

                </div>

                

                
                    
                        <div class="main-content">
                        <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 id="Sec1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">1 </span>Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Current state-of-the-art object detection systems are variants of the following approach: hypothesize bounding boxes, resample pixels or features for each box, and apply a high-quality classifier. This pipeline has prevailed on detection benchmarks since the Selective Search work&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W.: Selective search for object recognition. IJCV 104, 154 (2013)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR1" id="ref-link-section-d5248163e1052">1</a>] through the current leading results on PASCAL VOC, COCO, and ILSVRC detection all based on Faster R-CNN [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e1055">2</a>] albeit with deeper features such as [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR3" id="ref-link-section-d5248163e1058">3</a>]. While accurate, these approaches have been too computationally intensive for embedded systems and, even with high-end hardware, too slow for real-time applications. Often detection speed for these approaches is measured in frames per second, and even the fastest high-accuracy detector, Faster R-CNN, operates at only 7&nbsp;frames per second (FPS). There have been many attempts to build faster detectors by attacking each stage of the detection pipeline (see related work in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec12">4</a>), but so far, significantly increased speed comes only at the cost of significantly decreased detection accuracy.</p><p>This paper presents the first deep network based object detector that does not resample pixels or features for bounding box hypotheses and is as accurate as approaches that do. This results in a significant improvement in speed for high-accuracy detection (59&nbsp;FPS with mAP 74.3&nbsp;% on VOC2007 <span class="u-monospace">test</span>, vs Faster R-CNN 7&nbsp;FPS with mAP 73.2&nbsp;% or YOLO 45&nbsp;FPS with mAP 63.4&nbsp;%). The fundamental improvement in speed comes from eliminating bounding box proposals and the subsequent pixel or feature resampling stage. We are not the first to do this (cf. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR4" id="ref-link-section-d5248163e1070">4</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e1073">5</a>]), but by adding a series of improvements, we manage to increase the accuracy significantly over previous attempts. Our improvements include using a small convolutional filter to predict object categories and offsets in bounding box locations, using separate predictors (filters) for different aspect ratio detections, and applying these filters to multiple feature maps from the later stages of a network in order to perform detection at multiple scales. With these modifications—especially using multiple layers for prediction at different scales—we can achieve high-accuracy using relatively low resolution input, further increasing detection speed. While these contributions may seem small independently, we note that the resulting system improves accuracy on real-time detection for PASCAL VOC from 63.4&nbsp;% mAP for YOLO to 74.3&nbsp;% mAP for our SSD. This is a larger relative improvement in detection accuracy than that from the recent, very high-profile work on residual networks&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR3" id="ref-link-section-d5248163e1076">3</a>]. Furthermore, significantly improving the speed of high-quality detection can broaden the range of settings where computer vision is useful.</p><p>We summarize our contributions as follows:</p><ul class="u-list-style-dash">
                  <li>
                    <p>We introduce SSD, a single-shot detector for multiple categories that is faster than the previous state-of-the-art for single shot detectors (YOLO), and significantly more accurate, in fact as accurate as slower techniques that perform explicit region proposals and pooling (including Faster R-CNN).</p>
                  </li>
                  <li>
                    <p>The core of SSD is predicting category scores and box offsets for a fixed set of default bounding boxes using small convolutional filters applied to feature maps.</p>
                  </li>
                  <li>
                    <p>To achieve high detection accuracy we produce predictions of different scales from feature maps of different scales, and explicitly separate predictions by aspect ratio.</p>
                  </li>
                  <li>
                    <p>These design features lead to simple end-to-end training and high accuracy, even on low resolution input images, further improving the speed vs accuracy trade-off.</p>
                  </li>
                  <li>
                    <p>Experiments include timing and accuracy analysis on models with varying input size evaluated on PASCAL VOC, COCO, and ILSVRC and are compared to a range of recent state-of-the-art approaches.</p>
                  </li>
                </ul>
<div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig1_HTML.gif?as=webp"><img aria-describedby="Fig1" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/419956_1_En_2_Fig1_HTML.gif" alt="figure 1" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>
                <b>SSD framework.</b> (a) SSD only needs an input image and ground truth boxes for each object during training. In a convolutional fashion, we evaluate a small set (e.g. 4) of default boxes of different aspect ratios at each location in several feature maps with different scales (e.g. <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-11" style="width: 2.433em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 108%;"><span style="position: absolute; clip: rect(1.334em, 1002.2em, 2.376em, -999.997em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-12"><span class="mn" id="MathJax-Span-13" style="font-family: MathJax_Main;">8</span><span class="mo" id="MathJax-Span-14" style="font-family: MathJax_Main; padding-left: 0.234em;">×</span><span class="mn" id="MathJax-Span-15" style="font-family: MathJax_Main; padding-left: 0.234em;">8</span></span><span style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.878em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>8</mn><mo>×</mo><mn>8</mn></math></span></span><script type="math/tex" id="MathJax-Element-3">8 \times 8</script></span> and <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-16" style="width: 2.433em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 108%;"><span style="position: absolute; clip: rect(1.334em, 1002.2em, 2.376em, -999.997em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-17"><span class="mn" id="MathJax-Span-18" style="font-family: MathJax_Main;">4</span><span class="mo" id="MathJax-Span-19" style="font-family: MathJax_Main; padding-left: 0.234em;">×</span><span class="mn" id="MathJax-Span-20" style="font-family: MathJax_Main; padding-left: 0.234em;">4</span></span><span style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.878em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>4</mn></math></span></span><script type="math/tex" id="MathJax-Element-4">4 \times 4</script></span> in (b) and (c)). For each default box, we predict both the shape offsets and the confidences for all object categories (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-21" style="width: 6.658em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.137em; height: 0px; font-size: 108%;"><span style="position: absolute; clip: rect(1.276em, 1006.02em, 2.665em, -999.997em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-22"><span class="mo" id="MathJax-Span-23" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-24"><span style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-25" style="font-family: MathJax_Math-italic;">c</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span style="position: absolute; top: -3.817em; left: 0.408em;"><span class="mn" id="MathJax-Span-26" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span class="mo" id="MathJax-Span-27" style="font-family: MathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-28" style="padding-left: 0.177em;"><span style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-29" style="font-family: MathJax_Math-italic;">c</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span style="position: absolute; top: -3.817em; left: 0.408em;"><span class="mn" id="MathJax-Span-30" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span class="mo" id="MathJax-Span-31" style="font-family: MathJax_Main;">,</span><span class="mo" id="MathJax-Span-32" style="font-family: MathJax_Main; padding-left: 0.177em;">⋯</span><span class="mo" id="MathJax-Span-33" style="font-family: MathJax_Main; padding-left: 0.177em;">,</span><span class="msubsup" id="MathJax-Span-34" style="padding-left: 0.177em;"><span style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-35" style="font-family: MathJax_Math-italic;">c</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span style="position: absolute; top: -3.817em; left: 0.408em;"><span class="mi" id="MathJax-Span-36" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span class="mo" id="MathJax-Span-37" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><msub><mi>c</mi><mn>1</mn></msub><mo>,</mo><msub><mi>c</mi><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mi>c</mi><mi>p</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-5">(c_1, c_2, \cdots , c_p)</script></span>). At training time, we first match these default boxes to the ground truth boxes. For example, we have matched two default boxes with the cat and one with the dog, which are treated as positives and the rest as negatives. The model loss is a weighted sum between localization loss (e.g. Smooth L1&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Girshick, R.: Fast R-CNN. In: ICCV (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR6" id="ref-link-section-d5248163e1236">6</a>]) and confidence loss (e.g. Softmax).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section data-title="The Single Shot Detector (SSD)"><div class="c-article-section" id="Sec2-section"><h2 id="Sec2" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">2 </span>The Single Shot Detector (SSD)</h2><div class="c-article-section__content" id="Sec2-content"><p>This section describes our proposed SSD framework for detection (Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec3">2.1</a>) and the associated training methodology (Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec4">2.2</a>). Afterwards, Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec5">3</a> presents dataset-specific model details and experimental results.</p><h3 class="c-article__sub-heading" id="Sec3"><span class="c-article-section__title-number">2.1 </span>Model</h3><p>The SSD approach is based on a feed-forward convolutional network that produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections. The early network layers are based on a standard architecture used for high quality image classification (truncated before any classification layers), which we will call the base network<sup><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup>. We then add auxiliary structure to the network to produce detections with the following key features:</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig2_HTML.gif?as=webp"><img aria-describedby="Fig2" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/419956_1_En_2_Fig2_HTML.gif" alt="figure 2" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>A comparison between two single shot detection models: SSD and YOLO&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e1288">5</a>]. Our SSD model adds several feature layers to the end of a base network, which predict the offsets to default boxes of different scales and aspect ratios and their associated confidences. SSD with a <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-38" style="width: 4.575em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.227em; height: 0px; font-size: 108%;"><span style="position: absolute; clip: rect(1.334em, 1004.17em, 2.376em, -999.997em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-39"><span class="mn" id="MathJax-Span-40" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-41" style="font-family: MathJax_Main; padding-left: 0.234em;">×</span><span class="mn" id="MathJax-Span-42" style="font-family: MathJax_Main; padding-left: 0.234em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.878em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-6">300 \times 300</script></span> input size significantly outperforms its <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;448&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;448&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-43" style="width: 4.575em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.227em; height: 0px; font-size: 108%;"><span style="position: absolute; clip: rect(1.334em, 1004.17em, 2.376em, -999.997em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-44"><span class="mn" id="MathJax-Span-45" style="font-family: MathJax_Main;">448</span><span class="mo" id="MathJax-Span-46" style="font-family: MathJax_Main; padding-left: 0.234em;">×</span><span class="mn" id="MathJax-Span-47" style="font-family: MathJax_Main; padding-left: 0.234em;">448</span></span><span style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.878em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>448</mn><mo>×</mo><mn>448</mn></math></span></span><script type="math/tex" id="MathJax-Element-7">448 \times 448</script></span> YOLO counterpart in accuracy on VOC2007 <span class="u-monospace">test</span> while also improving the speed.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<p>
          <b>Multi-scale feature maps for detection.</b> We add convolutional feature layers to the end of the truncated base network. These layers decrease in size progressively and allow predictions of detections at multiple scales. The convolutional model for predicting detections is different for each feature layer (<i>cf</i> Overfeat [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR4" id="ref-link-section-d5248163e1364">4</a>] and YOLO [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e1367">5</a>] that operate on a single scale feature map).</p><p>
          <b>Convolutional predictors for detection.</b> Each added feature layer (or optionally an existing feature layer from the base network) can produce a fixed set of detection predictions using a set of convolutional filters. These are indicated on top of the SSD network architecture in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig2">2</a>. For a feature layer of size <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-48" style="width: 3.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.681em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.689em, 1002.68em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-49"><span class="mi" id="MathJax-Span-50" style="font-family: MathJax_Math-italic;">m</span><span class="mo" id="MathJax-Span-51" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mi" id="MathJax-Span-52" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">n</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.669em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi><mo>×</mo><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-8">m \times n</script></span> with <i>p</i> channels, the basic element for predicting parameters of a potential detection is a <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-53" style="width: 4.368em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.872em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1003.87em, 2.681em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-54"><span class="mn" id="MathJax-Span-55" style="font-family: MathJax_Main;">3</span><span class="mo" id="MathJax-Span-56" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-57" style="font-family: MathJax_Main; padding-left: 0.201em;">3</span><span class="mo" id="MathJax-Span-58" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mi" id="MathJax-Span-59" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">p</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.275em; border-left: 0px solid; width: 0px; height: 1.058em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo><mn>3</mn><mo>×</mo><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-9">3 \times 3 \times p</script></span> <i>small kernel</i> that produces either a score for a category, or a shape offset relative to the default box coordinates. At each of the <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-60" style="width: 3.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.681em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.689em, 1002.68em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-61"><span class="mi" id="MathJax-Span-62" style="font-family: MathJax_Math-italic;">m</span><span class="mo" id="MathJax-Span-63" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mi" id="MathJax-Span-64" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">n</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.669em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi><mo>×</mo><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-10">m \times n</script></span> locations where the kernel is applied, it produces an output value. The bounding box offset output values are measured relative to a default box position relative to each feature map location (<i>cf</i> the architecture of YOLO [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e1471">5</a>] that uses an intermediate fully connected layer instead of a convolutional filter for this step).</p><p>
          <b>Default boxes and aspect ratios.</b> We associate a set of default bounding boxes with each feature map cell, for multiple feature maps at the top of the network. The default boxes tile the feature map in a convolutional manner, so that the position of each box relative to its corresponding cell is fixed. At each feature map cell, we predict the offsets relative to the default box shapes in the cell, as well as the per-class scores that indicate the presence of a class instance in each of those boxes. Specifically, for each box out of <i>k</i> at a given location, we compute <i>c</i> class scores and the 4 offsets relative to the original default box shape. This results in a total of <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-65" style="width: 3.872em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.425em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.441em, 1003.42em, 2.731em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-66"><span class="mo" id="MathJax-Span-67" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-68" style="font-family: MathJax_Math-italic;">c</span><span class="mo" id="MathJax-Span-69" style="font-family: MathJax_Main; padding-left: 0.201em;">+</span><span class="mn" id="MathJax-Span-70" style="font-family: MathJax_Main; padding-left: 0.201em;">4</span><span class="mo" id="MathJax-Span-71" style="font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-72" style="font-family: MathJax_Math-italic;">k</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.225em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>c</mi><mo>+</mo><mn>4</mn><mo stretchy="false">)</mo><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-11">(c+4)k</script></span> filters that are applied around each location in the feature map, yielding <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-73" style="width: 5.508em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.913em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.441em, 1004.91em, 2.731em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-74"><span class="mo" id="MathJax-Span-75" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-76" style="font-family: MathJax_Math-italic;">c</span><span class="mo" id="MathJax-Span-77" style="font-family: MathJax_Main; padding-left: 0.201em;">+</span><span class="mn" id="MathJax-Span-78" style="font-family: MathJax_Main; padding-left: 0.201em;">4</span><span class="mo" id="MathJax-Span-79" style="font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-80" style="font-family: MathJax_Math-italic;">k</span><span class="mi" id="MathJax-Span-81" style="font-family: MathJax_Math-italic;">m</span><span class="mi" id="MathJax-Span-82" style="font-family: MathJax_Math-italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.225em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>c</mi><mo>+</mo><mn>4</mn><mo stretchy="false">)</mo><mi>k</mi><mi>m</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-12">(c+4)kmn</script></span> outputs for a <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-83" style="width: 3.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.681em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.689em, 1002.68em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-84"><span class="mi" id="MathJax-Span-85" style="font-family: MathJax_Math-italic;">m</span><span class="mo" id="MathJax-Span-86" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mi" id="MathJax-Span-87" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">n</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.669em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi><mo>×</mo><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">m\times n</script></span> feature map. For an illustration of default boxes, please refer to Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig1">1</a>. Our default boxes are similar to the <i>anchor boxes</i> used in Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e1593">2</a>], however we apply them to several feature maps of different resolutions. Allowing different default box shapes in several feature maps let us efficiently discretize the space of possible output box shapes.</p><h3 class="c-article__sub-heading" id="Sec4"><span class="c-article-section__title-number">2.2 </span>Training</h3><p>The key difference between training SSD and training a typical detector that uses region proposals, is that ground truth information needs to be assigned to specific outputs in the fixed set of detector outputs. Some version of this is also required for training in YOLO [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e1604">5</a>] and for the region proposal stage of Faster R-CNN [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e1607">2</a>] and MultiBox [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e1610">7</a>]. Once this assignment is determined, the loss function and back propagation are applied end-to-end. Training also involves choosing the set of default boxes and scales for detection as well as the hard negative mining and data augmentation strategies.</p><p>
          <b>Matching Strategy.</b> During training we need to determine which default boxes correspond to a ground truth detection and train the network accordingly. For each ground truth box we are selecting from default boxes that vary over location, aspect ratio, and scale. We begin by matching each ground truth box to the default box with the best Jaccard overlap (as in MultiBox&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e1619">7</a>]). Unlike MultiBox, we then match default boxes to any ground truth with Jaccard overlap higher than a threshold (0.5). This simplifies the learning problem, allowing the network to predict high scores for multiple overlapping default boxes rather than requiring it to pick only the one with maximum overlap.</p><p>
          <b>Training Objective.</b> The SSD training objective is derived from the MultiBox objective&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e1628">7</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Szegedy, C., Reed, S., Erhan, D., Anguelov, D.: Scalable, high-quality object detection. arXiv preprint v3 (2015). 
                    arXiv:1412.1441
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR8" id="ref-link-section-d5248163e1631">8</a>] but is extended to handle multiple object categories. Let <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;{&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;}&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-88" style="width: 5.608em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.012em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.391em, 1004.96em, 2.929em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-89"><span class="msubsup" id="MathJax-Span-90"><span style="display: inline-block; position: relative; width: 1.193em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.55em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-91" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.45em, 4.318em, -999.998em); top: -4.511em; left: 0.598em;"><span class="mi" id="MathJax-Span-92" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.6em, 4.318em, -999.998em); top: -3.718em; left: 0.598em;"><span class="texatom" id="MathJax-Span-93"><span class="mrow" id="MathJax-Span-94"><span class="mi" id="MathJax-Span-95" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-96" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-97" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="mo" id="MathJax-Span-98" style="font-family: MathJax_Main; padding-left: 0.3em;">{</span><span class="mn" id="MathJax-Span-99" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-100" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-101" style="font-family: MathJax_Main; padding-left: 0.151em;">0</span><span class="mo" id="MathJax-Span-102" style="font-family: MathJax_Main;">}</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.553em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mo>=</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo fence="false" stretchy="false">}</mo></math></span></span><script type="math/tex" id="MathJax-Element-14">x_{ij}^p = \{1,0\}</script></span> be an indicator for matching the <i>i</i>-th default box to the <i>j</i>-th ground truth box of category <i>p</i>. In the matching strategy above, we can have <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;&amp;#x2265;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-103" style="width: 5.161em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.616em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.391em, 1004.57em, 2.929em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-104"><span class="munderover" id="MathJax-Span-105"><span style="display: inline-block; position: relative; width: 1.391em; height: 0px;"><span style="position: absolute; clip: rect(3.127em, 1001em, 4.417em, -999.998em); top: -4.015em; left: 0em;"><span class="mo" id="MathJax-Span-106" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.718em; left: 1.044em;"><span class="mi" id="MathJax-Span-107" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-108" style="padding-left: 0.151em;"><span style="display: inline-block; position: relative; width: 1.193em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.55em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-109" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.45em, 4.318em, -999.998em); top: -4.511em; left: 0.598em;"><span class="mi" id="MathJax-Span-110" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.6em, 4.318em, -999.998em); top: -3.718em; left: 0.598em;"><span class="texatom" id="MathJax-Span-111"><span class="mrow" id="MathJax-Span-112"><span class="mi" id="MathJax-Span-113" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-114" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-115" style="font-family: MathJax_Main; padding-left: 0.3em;">≥</span><span class="mn" id="MathJax-Span-116" style="font-family: MathJax_Main; padding-left: 0.3em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.553em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo>∑</mo><mi>i</mi></munder><msubsup><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mo>≥</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-15">\sum _i x_{ij}^p \ge 1</script></span>. The overall objective loss function is a weighted sum of the localization loss (loc) and the confidence loss (conf):</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: left;"><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" style="text-align: left; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable columnalign=&quot;right left right left right left right left right left right left&quot; rowspacing=&quot;3pt&quot; columnspacing=&quot;0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em&quot; displaystyle=&quot;true&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-117" style="width: 21.381em; display: inline-block;"><span style="display: inline-block; position: relative; width: 19.1em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(0.945em, 1019em, 3.227em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-118"><span class="mtable" id="MathJax-Span-119"><span style="display: inline-block; position: relative; width: 18.802em; height: 0px; margin-right: 0.151em; margin-left: 0.151em;"><span style="position: absolute; clip: rect(2.631em, 1018.7em, 4.913em, -999.998em); top: -4.015em; left: 0em;"><span style="display: inline-block; position: relative; width: 18.802em; height: 0px;"><span style="position: absolute; clip: rect(2.532em, 1018.7em, 4.864em, -999.998em); top: -3.916em; right: 0em;"><span class="mtd" id="MathJax-Span-120"><span class="mrow" id="MathJax-Span-121"><span class="mi" id="MathJax-Span-122" style="font-family: MathJax_Math-italic;">L</span><span class="mo" id="MathJax-Span-123" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-124" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-125" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-126" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">c</span><span class="mo" id="MathJax-Span-127" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-128" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">l</span><span class="mo" id="MathJax-Span-129" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-130" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">g<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-131" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-132" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="mfrac" id="MathJax-Span-133" style="padding-left: 0.3em;"><span style="display: inline-block; position: relative; width: 0.995em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.227em, 1000.45em, 4.169em, -999.998em); top: -4.71em; left: 50%; margin-left: -0.246em;"><span class="mn" id="MathJax-Span-134" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.177em, 1000.89em, 4.169em, -999.998em); top: -3.321em; left: 50%; margin-left: -0.444em;"><span class="mi" id="MathJax-Span-135" style="font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.102em;"></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1001em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.995em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-136" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-137"><span style="display: inline-block; position: relative; width: 2.235em; height: 0px;"><span style="position: absolute; clip: rect(3.177em, 1000.65em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-138" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.697em;"><span class="texatom" id="MathJax-Span-139"><span class="mrow" id="MathJax-Span-140"><span class="mi" id="MathJax-Span-141" style="font-size: 70.7%; font-family: MathJax_Math-italic;">c</span><span class="mi" id="MathJax-Span-142" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-143" style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span class="mi" id="MathJax-Span-144" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.052em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-145" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-146" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-147" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-148" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">c</span><span class="mo" id="MathJax-Span-149" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-150" style="font-family: MathJax_Main; padding-left: 0.201em;">+</span><span class="mi" id="MathJax-Span-151" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">α</span><span class="msubsup" id="MathJax-Span-152"><span style="display: inline-block; position: relative; width: 1.639em; height: 0px;"><span style="position: absolute; clip: rect(3.177em, 1000.65em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-153" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.697em;"><span class="texatom" id="MathJax-Span-154"><span class="mrow" id="MathJax-Span-155"><span class="mi" id="MathJax-Span-156" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span><span class="mi" id="MathJax-Span-157" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-158" style="font-size: 70.7%; font-family: MathJax_Math-italic;">c</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-159" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-160" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-161" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-162" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">l</span><span class="mo" id="MathJax-Span-163" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-164" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">g<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-165" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-166" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.886em; border-left: 0px solid; width: 0px; height: 2.392em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mtr><mtd><mi>L</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>g</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mo stretchy="false">(</mo><msub><mi>L</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi><mi>o</mi><mi>n</mi><mi>f</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><msub><mi>L</mi><mrow class="MJX-TeXAtom-ORD"><mi>l</mi><mi>o</mi><mi>c</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>g</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mtd></mtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-16">\begin{aligned} L(x, c, l, g) = \frac{1}{N}(L_{conf}(x, c) + \alpha L_{loc}(x, l, g)) \end{aligned}</script></span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>where N is the number of matched default boxes, and the localization loss is the Smooth L1 loss&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Girshick, R.: Fast R-CNN. In: ICCV (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR6" id="ref-link-section-d5248163e1889">6</a>] between the predicted box (<i>l</i>) and the ground truth box (<i>g</i>) parameters. Similar to Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e1899">2</a>], we regress to offsets for the center of the bounding box and for its width and height. Our confidence loss is the softmax loss over multiple classes confidences (<i>c</i>) and the weight term <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-167" style="width: 0.747em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.647em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.739em, 1000.6em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-168"><span class="mi" id="MathJax-Span-169" style="font-family: MathJax_Math-italic;">α</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.614em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi></math></span></span><script type="math/tex" id="MathJax-Element-17">\alpha </script></span> is set to 1 by cross validation.</p><p>
          <b>Choosing Scales and Aspect Ratios for Default Boxes.</b> To handle different object scales, some methods&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR4" id="ref-link-section-d5248163e1931">4</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="He, K., Zhang, X., Ren, S., Sun, J.: Spatial pyramid pooling in deep convolutional networks for visual recognition. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8691, pp. 346–361. Springer, Heidelberg (2014). doi:
                    10.1007/978-3-319-10578-9_23
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR9" id="ref-link-section-d5248163e1934">9</a>] suggest processing the image at different sizes and combining the results afterwards. However, by utilizing feature maps from several different layers in a single network for prediction we can mimic the same effect, while also sharing parameters across all object scales. Previous works&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: CVPR (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR10" id="ref-link-section-d5248163e1937">10</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Hariharan, B., Arbeláez, P., Girshick, R., Malik, J.: Hypercolumns for object segmentation and fine-grained localization. In: CVPR (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR11" id="ref-link-section-d5248163e1940">11</a>] have shown that using feature maps from the lower layers can improve semantic segmentation quality because the lower layers capture more fine details of the input objects. Similarly,&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Liu, W., Rabinovich, A., Berg, A.C.: ParseNet: looking wider to see better. In: ILCR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR12" id="ref-link-section-d5248163e1944">12</a>] showed that adding global context pooled from a feature map can help smooth the segmentation results. Motivated by these methods, we use both the lower and upper feature maps for detection. Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig1">1</a> shows two exemplar feature maps (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-170" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-171"><span class="mn" id="MathJax-Span-172" style="font-family: MathJax_Main;">8</span><span class="mo" id="MathJax-Span-173" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-174" style="font-family: MathJax_Main; padding-left: 0.201em;">8</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>8</mn><mo>×</mo><mn>8</mn></math></span></span><script type="math/tex" id="MathJax-Element-18">8 \times 8</script></span> and <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-175" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.491em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-176"><span class="mn" id="MathJax-Span-177" style="font-family: MathJax_Main;">4</span><span class="mo" id="MathJax-Span-178" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-179" style="font-family: MathJax_Main; padding-left: 0.201em;">4</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>4</mn></math></span></span><script type="math/tex" id="MathJax-Element-19">4\times 4</script></span>) which are used in the framework. In practice, we can use many more with small computational overhead.</p><p>We design the tiling of default boxes so that specific feature maps learn to be responsive to particular scales of the objects. Suppose we want to use <i>m</i> feature maps for prediction. The scale of the default boxes for each feature map is computed as:</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: left;"><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" style="text-align: left; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable columnalign=&quot;right left right left right left right left right left right left&quot; rowspacing=&quot;3pt&quot; columnspacing=&quot;0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em&quot; displaystyle=&quot;true&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;min&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;max&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;min&lt;/mtext&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-180" style="width: 21.53em; display: inline-block;"><span style="display: inline-block; position: relative; width: 19.199em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(0.945em, 1019.1em, 3.227em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-181"><span class="mtable" id="MathJax-Span-182"><span style="display: inline-block; position: relative; width: 18.901em; height: 0px; margin-right: 0.151em; margin-left: 0.151em;"><span style="position: absolute; clip: rect(2.631em, 1018.75em, 4.913em, -999.998em); top: -4.015em; left: 0em;"><span style="display: inline-block; position: relative; width: 18.901em; height: 0px;"><span style="position: absolute; clip: rect(2.631em, 1018.75em, 4.913em, -999.998em); top: -4.015em; right: 0em;"><span class="mtd" id="MathJax-Span-183"><span class="mrow" id="MathJax-Span-184"><span class="msubsup" id="MathJax-Span-185"><span style="display: inline-block; position: relative; width: 0.895em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-186" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mi" id="MathJax-Span-187" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-188" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="msubsup" id="MathJax-Span-189" style="padding-left: 0.3em;"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-190" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mtext" id="MathJax-Span-191" style="font-size: 70.7%; font-family: MathJax_Main;">min</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-192" style="font-family: MathJax_Main; padding-left: 0.201em;">+</span><span class="mfrac" id="MathJax-Span-193" style="padding-left: 0.201em;"><span style="display: inline-block; position: relative; width: 4.864em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.276em, 1004.76em, 4.318em, -999.998em); top: -4.71em; left: 50%; margin-left: -2.378em;"><span class="mrow" id="MathJax-Span-194"><span class="msubsup" id="MathJax-Span-195"><span style="display: inline-block; position: relative; width: 1.838em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-196" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mtext" id="MathJax-Span-197" style="font-size: 70.7%; font-family: MathJax_Main;">max</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-198" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="msubsup" id="MathJax-Span-199" style="padding-left: 0.201em;"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-200" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mtext" id="MathJax-Span-201" style="font-size: 70.7%; font-family: MathJax_Main;">min</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.227em, 1002.48em, 4.268em, -999.998em); top: -3.321em; left: 50%; margin-left: -1.287em;"><span class="mrow" id="MathJax-Span-202"><span class="mi" id="MathJax-Span-203" style="font-family: MathJax_Math-italic;">m</span><span class="mo" id="MathJax-Span-204" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="mn" id="MathJax-Span-205" style="font-family: MathJax_Main; padding-left: 0.201em;">1</span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1004.86em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.864em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-206" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-207" style="font-family: MathJax_Math-italic;">k</span><span class="mo" id="MathJax-Span-208" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="mn" id="MathJax-Span-209" style="font-family: MathJax_Main; padding-left: 0.201em;">1</span><span class="mo" id="MathJax-Span-210" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-211" style="font-family: MathJax_Main;">,</span><span class="mspace" id="MathJax-Span-212" style="height: 0em; vertical-align: 0em; width: 0.995em; display: inline-block; overflow: hidden;"></span><span class="mi" id="MathJax-Span-213" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">k</span><span class="mo" id="MathJax-Span-214" style="font-family: MathJax_Main; padding-left: 0.3em;">∈</span><span class="mo" id="MathJax-Span-215" style="font-family: MathJax_Main; padding-left: 0.3em;">[</span><span class="mn" id="MathJax-Span-216" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-217" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-218" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">m</span><span class="mo" id="MathJax-Span-219" style="font-family: MathJax_Main;">]</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.886em; border-left: 0px solid; width: 0px; height: 2.392em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mtr><mtd><msub><mi>s</mi><mi>k</mi></msub><mo>=</mo><msub><mi>s</mi><mtext>min</mtext></msub><mo>+</mo><mfrac><mrow><msub><mi>s</mi><mtext>max</mtext></msub><mo>−</mo><msub><mi>s</mi><mtext>min</mtext></msub></mrow><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></mfrac><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>,</mo><mspace width="1em"></mspace><mi>k</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mi>m</mi><mo stretchy="false">]</mo></mtd></mtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-20">\begin{aligned} s_k = s_\text {min} + \frac{s_\text {max} - s_\text {min}}{m - 1} (k - 1),\quad k\in [1, m] \end{aligned}</script></span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p>where <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;min&lt;/mtext&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-220" style="width: 1.937em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.739em, 1001.74em, 2.631em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-221"><span class="msubsup" id="MathJax-Span-222"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-223" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mtext" id="MathJax-Span-224" style="font-size: 70.7%; font-family: MathJax_Main;">min</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.219em; border-left: 0px solid; width: 0px; height: 0.781em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mtext>min</mtext></msub></math></span></span><script type="math/tex" id="MathJax-Element-21">s_\text {min}</script></span> is 0.2 and <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;max&lt;/mtext&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-225" style="width: 2.086em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.838em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.739em, 1001.84em, 2.631em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-226"><span class="msubsup" id="MathJax-Span-227"><span style="display: inline-block; position: relative; width: 1.838em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-228" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mtext" id="MathJax-Span-229" style="font-size: 70.7%; font-family: MathJax_Main;">max</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.219em; border-left: 0px solid; width: 0px; height: 0.781em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mtext>max</mtext></msub></math></span></span><script type="math/tex" id="MathJax-Element-22">s_\text {max}</script></span> is 0.9, meaning the lowest layer has a scale of 0.2 and the highest layer has a scale of 0.9, and all layers in between are regularly spaced. We impose different aspect ratios for the default boxes, and denote them as <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;{&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;}&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-230" style="width: 8.782em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.84em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1007.79em, 2.879em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-231"><span class="msubsup" id="MathJax-Span-232"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.5em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-233" style="font-family: MathJax_Math-italic;">a</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.548em;"><span class="mi" id="MathJax-Span-234" style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-235" style="font-family: MathJax_Main; padding-left: 0.3em;">∈</span><span class="mo" id="MathJax-Span-236" style="font-family: MathJax_Main; padding-left: 0.3em;">{</span><span class="mn" id="MathJax-Span-237" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-238" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-239" style="font-family: MathJax_Main; padding-left: 0.151em;">2</span><span class="mo" id="MathJax-Span-240" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-241" style="font-family: MathJax_Main; padding-left: 0.151em;">3</span><span class="mo" id="MathJax-Span-242" style="font-family: MathJax_Main;">,</span><span class="mfrac" id="MathJax-Span-243" style="padding-left: 0.151em;"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-244" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-245" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-246" style="font-family: MathJax_Main;">,</span><span class="mfrac" id="MathJax-Span-247" style="padding-left: 0.151em;"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-248" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.35em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-249" style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-250" style="font-family: MathJax_Main;">}</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>a</mi><mi>r</mi></msub><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>,</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo fence="false" stretchy="false">}</mo></math></span></span><script type="math/tex" id="MathJax-Element-23">a_r \in \{1, 2, 3, \frac{1}{2}, \frac{1}{3}\}</script></span>. We can compute the width (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;msqrt&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/msub&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-251" style="width: 5.856em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1005.21em, 2.83em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-252"><span class="msubsup" id="MathJax-Span-253"><span style="display: inline-block; position: relative; width: 1.143em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.7em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-254" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.45em, 4.169em, -999.998em); top: -4.363em; left: 0.697em;"><span class="mi" id="MathJax-Span-255" style="font-size: 70.7%; font-family: MathJax_Math-italic;">a</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.375em, 1000.45em, 4.169em, -999.998em); top: -3.668em; left: 0.697em;"><span class="mi" id="MathJax-Span-256" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-257" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="msubsup" id="MathJax-Span-258" style="padding-left: 0.3em;"><span style="display: inline-block; position: relative; width: 0.895em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-259" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mi" id="MathJax-Span-260" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="msqrt" id="MathJax-Span-261"><span style="display: inline-block; position: relative; width: 1.788em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.95em, 4.318em, -999.998em); top: -4.015em; left: 0.846em;"><span class="mrow" id="MathJax-Span-262"><span class="msubsup" id="MathJax-Span-263"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.5em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-264" style="font-family: MathJax_Math-italic;">a</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.548em;"><span class="mi" id="MathJax-Span-265" style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.95em, 3.921em, -999.998em); top: -4.363em; left: 0.846em;"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: -0.097em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: 0.25em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.078em, 1000.85em, 4.368em, -999.998em); top: -3.867em; left: 0em;"><span style="font-family: MathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left: 0px solid; width: 0px; height: 1.225em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>w</mi><mi>k</mi><mi>a</mi></msubsup><mo>=</mo><msub><mi>s</mi><mi>k</mi></msub><msqrt><msub><mi>a</mi><mi>r</mi></msub></msqrt></math></span></span><script type="math/tex" id="MathJax-Element-24">w_k^a = s_k\sqrt{a_r}</script></span>) and height (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;msqrt&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/msub&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-266" style="width: 6.302em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.608em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.441em, 1005.61em, 2.83em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-267"><span class="msubsup" id="MathJax-Span-268"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px;"><span style="position: absolute; clip: rect(3.177em, 1000.55em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-269" style="font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.45em, 4.169em, -999.998em); top: -4.363em; left: 0.598em;"><span class="mi" id="MathJax-Span-270" style="font-size: 70.7%; font-family: MathJax_Math-italic;">a</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.375em, 1000.45em, 4.169em, -999.998em); top: -3.668em; left: 0.598em;"><span class="mi" id="MathJax-Span-271" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-272" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="msubsup" id="MathJax-Span-273" style="padding-left: 0.3em;"><span style="display: inline-block; position: relative; width: 0.895em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-274" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mi" id="MathJax-Span-275" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="texatom" id="MathJax-Span-276"><span class="mrow" id="MathJax-Span-277"><span class="mo" id="MathJax-Span-278" style="font-family: MathJax_Main;">/</span></span></span><span class="msqrt" id="MathJax-Span-279"><span style="display: inline-block; position: relative; width: 1.788em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.95em, 4.318em, -999.998em); top: -4.015em; left: 0.846em;"><span class="mrow" id="MathJax-Span-280"><span class="msubsup" id="MathJax-Span-281"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.5em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-282" style="font-family: MathJax_Math-italic;">a</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.548em;"><span class="mi" id="MathJax-Span-283" style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1000.95em, 3.921em, -999.998em); top: -4.363em; left: 0.846em;"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: -0.097em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: 0.25em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.078em, 1000.85em, 4.368em, -999.998em); top: -3.867em; left: 0em;"><span style="font-family: MathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left: 0px solid; width: 0px; height: 1.336em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>h</mi><mi>k</mi><mi>a</mi></msubsup><mo>=</mo><msub><mi>s</mi><mi>k</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><msqrt><msub><mi>a</mi><mi>r</mi></msub></msqrt></math></span></span><script type="math/tex" id="MathJax-Element-25">h_k^a = s_k / \sqrt{a_r}</script></span>) for each default box. For the aspect ratio of 1, we also add a default box whose scale is <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2032;&lt;/mo&gt;&lt;/msubsup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msqrt&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-284" style="width: 6.55em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.856em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.491em, 1005.86em, 2.83em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-285"><span class="msubsup" id="MathJax-Span-286"><span style="display: inline-block; position: relative; width: 0.895em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-287" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.475em, 1000.25em, 4.12em, -999.998em); top: -4.313em; left: 0.449em;"><span class="mo" id="MathJax-Span-288" style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.375em, 1000.45em, 4.169em, -999.998em); top: -3.668em; left: 0.449em;"><span class="mi" id="MathJax-Span-289" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="mo" id="MathJax-Span-290" style="font-family: MathJax_Main; padding-left: 0.3em;">=</span><span class="msqrt" id="MathJax-Span-291" style="padding-left: 0.3em;"><span style="display: inline-block; position: relative; width: 3.574em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1002.73em, 4.368em, -999.998em); top: -4.015em; left: 0.846em;"><span class="mrow" id="MathJax-Span-292"><span class="msubsup" id="MathJax-Span-293"><span style="display: inline-block; position: relative; width: 0.895em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-294" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="mi" id="MathJax-Span-295" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-296"><span style="display: inline-block; position: relative; width: 1.838em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.4em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-297" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.449em;"><span class="texatom" id="MathJax-Span-298"><span class="mrow" id="MathJax-Span-299"><span class="mi" id="MathJax-Span-300" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span class="mo" id="MathJax-Span-301" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-302" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.574em, 1002.68em, 3.921em, -999.998em); top: -4.363em; left: 0.846em;"><span style="display: inline-block; position: relative; width: 2.681em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: -0.097em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -4.015em; left: 1.987em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.015em; left: 0.449em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.015em; left: 0.995em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.015em; left: 1.54em;">−<span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.078em, 1000.85em, 4.368em, -999.998em); top: -3.867em; left: 0em;"><span style="font-family: MathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.442em; border-left: 0px solid; width: 0px; height: 1.336em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>s</mi><mi>k</mi><mo>′</mo></msubsup><mo>=</mo><msqrt><msub><mi>s</mi><mi>k</mi></msub><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub></msqrt></math></span></span><script type="math/tex" id="MathJax-Element-26">s'_k = \sqrt{s_k s_{k+1}}</script></span>, resulting in 6 default boxes per feature map location. We set the center of each default box to <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-303" style="width: 6.004em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.36em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.143em, 1005.26em, 3.078em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-304"><span class="mo" id="MathJax-Span-305" style="font-family: MathJax_Main;">(</span><span class="mfrac" id="MathJax-Span-306"><span style="display: inline-block; position: relative; width: 1.838em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1001.64em, 4.219em, -999.998em); top: -4.462em; left: 50%; margin-left: -0.841em;"><span class="mrow" id="MathJax-Span-307"><span class="mi" id="MathJax-Span-308" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-309" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-310" style="font-size: 70.7%; font-family: MathJax_Main;">0.5</span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.326em, 1001em, 4.368em, -999.998em); top: -3.569em; left: 50%; margin-left: -0.543em;"><span class="mrow" id="MathJax-Span-311"><span class="texatom" id="MathJax-Span-312"><span class="mrow" id="MathJax-Span-313"><span class="mo" id="MathJax-Span-314" style="font-size: 70.7%; font-family: MathJax_Main;">|</span></span></span><span class="msubsup" id="MathJax-Span-315"><span style="display: inline-block; position: relative; width: 0.647em; height: 0px;"><span style="position: absolute; clip: rect(3.375em, 1000.4em, 4.318em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-316" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.052em;"></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.35em;"><span class="mi" id="MathJax-Span-317" style="font-size: 50%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="texatom" id="MathJax-Span-318"><span class="mrow" id="MathJax-Span-319"><span class="mo" id="MathJax-Span-320" style="font-size: 70.7%; font-family: MathJax_Main;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1001.84em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.838em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-321" style="font-family: MathJax_Main;">,</span><span class="mfrac" id="MathJax-Span-322" style="padding-left: 0.151em;"><span style="display: inline-block; position: relative; width: 1.887em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1001.69em, 4.318em, -999.998em); top: -4.561em; left: 50%; margin-left: -0.89em;"><span class="mrow" id="MathJax-Span-323"><span class="mi" id="MathJax-Span-324" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-325" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mn" id="MathJax-Span-326" style="font-size: 70.7%; font-family: MathJax_Main;">0.5</span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.326em, 1001em, 4.368em, -999.998em); top: -3.569em; left: 50%; margin-left: -0.543em;"><span class="mrow" id="MathJax-Span-327"><span class="texatom" id="MathJax-Span-328"><span class="mrow" id="MathJax-Span-329"><span class="mo" id="MathJax-Span-330" style="font-size: 70.7%; font-family: MathJax_Main;">|</span></span></span><span class="msubsup" id="MathJax-Span-331"><span style="display: inline-block; position: relative; width: 0.647em; height: 0px;"><span style="position: absolute; clip: rect(3.375em, 1000.4em, 4.318em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-332" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.052em;"></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.35em;"><span class="mi" id="MathJax-Span-333" style="font-size: 50%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="texatom" id="MathJax-Span-334"><span class="mrow" id="MathJax-Span-335"><span class="mo" id="MathJax-Span-336" style="font-size: 70.7%; font-family: MathJax_Main;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1001.89em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.887em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-337" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.719em; border-left: 0px solid; width: 0px; height: 1.947em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mfrac><mrow><mi>i</mi><mo>+</mo><mn>0.5</mn></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>f</mi><mi>k</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac><mo>,</mo><mfrac><mrow><mi>j</mi><mo>+</mo><mn>0.5</mn></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>f</mi><mi>k</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-27">(\frac{i+0.5}{|f_k|}, \frac{j+0.5}{|f_k|})</script></span>, where <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-338" style="width: 1.689em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.491em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.441em, 1001.39em, 2.731em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-339"><span class="texatom" id="MathJax-Span-340"><span class="mrow" id="MathJax-Span-341"><span class="mo" id="MathJax-Span-342" style="font-family: MathJax_Main;">|</span></span></span><span class="msubsup" id="MathJax-Span-343"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; clip: rect(3.177em, 1000.55em, 4.368em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-344" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.052em;"></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.499em;"><span class="mi" id="MathJax-Span-345" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="texatom" id="MathJax-Span-346"><span class="mrow" id="MathJax-Span-347"><span class="mo" id="MathJax-Span-348" style="font-family: MathJax_Main;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.225em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>f</mi><mi>k</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-28">|f_k|</script></span> is the size of the <i>k</i>-th square feature map, <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-349" style="width: 6.252em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.558em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.441em, 1005.46em, 2.731em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-350"><span class="mi" id="MathJax-Span-351" style="font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-352" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-353" style="font-family: MathJax_Math-italic; padding-left: 0.151em;">j</span><span class="mo" id="MathJax-Span-354" style="font-family: MathJax_Main; padding-left: 0.3em;">∈</span><span class="mo" id="MathJax-Span-355" style="font-family: MathJax_Main; padding-left: 0.3em;">[</span><span class="mn" id="MathJax-Span-356" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-357" style="font-family: MathJax_Main;">,</span><span class="texatom" id="MathJax-Span-358" style="padding-left: 0.151em;"><span class="mrow" id="MathJax-Span-359"><span class="mo" id="MathJax-Span-360" style="font-family: MathJax_Main;">|</span></span></span><span class="msubsup" id="MathJax-Span-361"><span style="display: inline-block; position: relative; width: 0.945em; height: 0px;"><span style="position: absolute; clip: rect(3.177em, 1000.55em, 4.368em, -999.998em); top: -4.015em; left: 0em;"><span class="mi" id="MathJax-Span-362" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.052em;"></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -3.867em; left: 0.499em;"><span class="mi" id="MathJax-Span-363" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span><span class="texatom" id="MathJax-Span-364"><span class="mrow" id="MathJax-Span-365"><span class="mo" id="MathJax-Span-366" style="font-family: MathJax_Main;">|</span></span></span><span class="mo" id="MathJax-Span-367" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.225em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi><mo>,</mo><mi>j</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mi>f</mi><mi>k</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-29">i, j\in [0, |f_k|)</script></span>. In practice, one can also design a distribution of default boxes to best fit a specific dataset.</p><p>By combining predictions for all default boxes with different scales and aspect ratios from all locations of many feature maps, we have a diverse set of predictions, covering various input object sizes and shapes. For example, in Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig1">1</a>, the dog is matched to a default box in the <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-368" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.491em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-369"><span class="mn" id="MathJax-Span-370" style="font-family: MathJax_Main;">4</span><span class="mo" id="MathJax-Span-371" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-372" style="font-family: MathJax_Main; padding-left: 0.201em;">4</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>4</mn></math></span></span><script type="math/tex" id="MathJax-Element-30">4 \times 4</script></span> feature map, but not to any default boxes in the <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-373" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-374"><span class="mn" id="MathJax-Span-375" style="font-family: MathJax_Main;">8</span><span class="mo" id="MathJax-Span-376" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-377" style="font-family: MathJax_Main; padding-left: 0.201em;">8</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>8</mn><mo>×</mo><mn>8</mn></math></span></span><script type="math/tex" id="MathJax-Element-31">8 \times 8</script></span> feature map. This is because those boxes have different scales and do not match the dog box, and therefore are considered as negatives during training.</p><p>
          <b>Hard Negative Mining.</b> After the matching step, most of the default boxes are negatives, especially when the number of possible default boxes is large. This introduces a significant imbalance between the positive and negative training examples. Instead of using all the negative examples, we sort them using the highest confidence loss for each default box and pick the top ones so that the ratio between the negatives and positives is at most 3:1. We found that this leads to faster optimization and a more stable training.</p><p>
          <b>Data Augmentation.</b> To make the model more robust to various input object sizes and shapes, each training image is randomly sampled by one of the following options:</p><ul class="u-list-style-dash">
                    <li>
                      <p>Use the entire original input image.</p>
                    </li>
                    <li>
                      <p>Sample a patch so that the <i>minimum</i> Jaccard overlap with the objects is 0.1, 0.3, 0.5, 0.7, or 0.9.</p>
                    </li>
                    <li>
                      <p>Randomly sample a patch.</p>
                    </li>
                  </ul>
<p>The size of each sampled patch is [0.1, 1] of the original image size, and the aspect ratio is between <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-378" style="width: 0.796em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1000.7em, 2.879em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-379"><span class="mfrac" id="MathJax-Span-380"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-381" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-382" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>2</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-32">\frac{1}{2}</script></span> and 2. We keep the overlapped part of the ground truth box if the center of it is in the sampled patch. After the aforementioned sampling step, each sampled patch is resized to fixed size and is horizontally flipped with probability of 0.5, in addition to applying some photo-metric distortions similar to those described in&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Howard, A.G.: Some improvements on deep convolutional neural network based image classification. arXiv preprint (2013). 
                    arXiv:1312.5402
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR13" id="ref-link-section-d5248163e2716">13</a>].</p></div></div></section><section data-title="Experimental Results"><div class="c-article-section" id="Sec5-section"><h2 id="Sec5" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">3 </span>Experimental Results</h2><div class="c-article-section__content" id="Sec5-content"><p>
        <b>Base Network.</b> Our experiments are all based on VGG16&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR14" id="ref-link-section-d5248163e2731">14</a>], which is pre-trained on the ILSVRC CLS-LOC dataset&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: Imagenet large scale visual recognition challenge. IJCV 115, 211 (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR15" id="ref-link-section-d5248163e2734">15</a>]. Similar to DeepLab-LargeFOV&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Semantic image segmentation with deep convolutional nets and fully connected CRFs. In: ICLR (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR16" id="ref-link-section-d5248163e2737">16</a>], we convert fc6 and fc7 to convolutional layers, subsample parameters from fc6 and fc7, change pool5 from <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-383" style="width: 4.864em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.318em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.27em, 2.582em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-384"><span class="mn" id="MathJax-Span-385" style="font-family: MathJax_Main;">2</span><span class="mo" id="MathJax-Span-386" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-387" style="font-family: MathJax_Main; padding-left: 0.201em;">2</span><span class="mo" id="MathJax-Span-388" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="mi" id="MathJax-Span-389" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">s</span><span class="mn" id="MathJax-Span-390" style="font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.164em; border-left: 0px solid; width: 0px; height: 0.947em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mo>×</mo><mn>2</mn><mo>−</mo><mi>s</mi><mn>2</mn></math></span></span><script type="math/tex" id="MathJax-Element-33">2 \times 2-s2</script></span> to <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-391" style="width: 4.864em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.318em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.27em, 2.582em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-392"><span class="mn" id="MathJax-Span-393" style="font-family: MathJax_Main;">3</span><span class="mo" id="MathJax-Span-394" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-395" style="font-family: MathJax_Main; padding-left: 0.201em;">3</span><span class="mo" id="MathJax-Span-396" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="mi" id="MathJax-Span-397" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">s</span><span class="mn" id="MathJax-Span-398" style="font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.164em; border-left: 0px solid; width: 0px; height: 0.947em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo><mn>3</mn><mo>−</mo><mi>s</mi><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-34">3\times 3-s1</script></span>, and use the atrous algorithm to fill the “holes”. We remove all the dropout layers and the fc8 layer. We fine-tune the resulting model using SGD with initial learning rate <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-399" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-400"><span class="msubsup" id="MathJax-Span-401"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-402" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-403"><span class="mrow" id="MathJax-Span-404"><span class="mo" id="MathJax-Span-405" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-406" style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>3</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-35">10^{-3}</script></span>, 0.9 momentum, 0.0005 weight decay, and batch size 32. The learning rate decay policy is slightly different for each dataset, and we will describe details later. The full training and testing code is built on Caffe&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: convolutional architecture for fast feature embedding. In: MM. ACM (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR17" id="ref-link-section-d5248163e2836">17</a>] and is open source at <a href="https://github.com/weiliu89/caffe/tree/ssd">https://github.com/weiliu89/caffe/tree/ssd</a>.</p><h3 class="c-article__sub-heading" id="Sec6"><span class="c-article-section__title-number">3.1 </span>PASCAL VOC2007</h3><p>On this dataset, we compare against Fast R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Girshick, R.: Fast R-CNN. In: ICCV (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR6" id="ref-link-section-d5248163e2853">6</a>] and Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e2856">2</a>] on VOC2007 <span class="u-monospace">test</span> (4952 images). All methods use the same pre-trained VGG16 network.</p><p>Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig2">2</a> shows the architecture details of the SSD300 model. We use conv4_3, conv7 (fc7), conv8_2, conv9_2, conv10_2, and conv11_2 to predict both location and confidences<sup><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup>. We initialize the parameters for all the newly added convolutional layers with the “xavier” method&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Glorot, X., Bengio, Y.: Understanding the difficulty of training deep feedforward neural networks. In: AISTATS (2010)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR18" id="ref-link-section-d5248163e2874">18</a>]. For conv4_3, conv10_2 and conv11_2, we only associate 4 default boxes at each feature map location – omitting aspect ratios of <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-407" style="width: 0.796em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1000.7em, 2.879em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-408"><span class="mfrac" id="MathJax-Span-409"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-410" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.35em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-411" style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>3</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-36">\frac{1}{3}</script></span> and 3. For all other layers, we put 6 default boxes as described in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec4">2.2</a>. Since, as pointed out in&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Liu, W., Rabinovich, A., Berg, A.C.: ParseNet: looking wider to see better. In: ILCR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR12" id="ref-link-section-d5248163e2905">12</a>], conv4_3 has a different feature scale compared to the other layers, we use the L2 normalization technique introduced in&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Liu, W., Rabinovich, A., Berg, A.C.: ParseNet: looking wider to see better. In: ILCR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR12" id="ref-link-section-d5248163e2908">12</a>] to scale the feature norm at each location in the feature map to 20 and learn the scale during back propagation. We use the <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-412" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-413"><span class="msubsup" id="MathJax-Span-414"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-415" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-416"><span class="mrow" id="MathJax-Span-417"><span class="mo" id="MathJax-Span-418" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-419" style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>3</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-37">10^{-3}</script></span> learning rate for 40k iterations, then we continue training for 10k iterations with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-38-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-420" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-421"><span class="msubsup" id="MathJax-Span-422"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-423" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-424"><span class="mrow" id="MathJax-Span-425"><span class="mo" id="MathJax-Span-426" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-427" style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-38">10^{-4}</script></span> and <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-39-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-428" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-429"><span class="msubsup" id="MathJax-Span-430"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-431" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-432"><span class="mrow" id="MathJax-Span-433"><span class="mo" id="MathJax-Span-434" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-435" style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>5</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-39">10^{-5}</script></span>. When training on VOC2007 <span class="u-monospace">trainval</span>, Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab1">1</a> shows that our low resolution SSD300 model is already more accurate than Fast R-CNN. When we train SSD on a larger <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-436" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-437"><span class="mn" id="MathJax-Span-438" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-439" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-440" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-40">512\times 512</script></span> input image it is even more accurate, surpassing Faster R-CNN by 1.7&nbsp;% mAP. If we train SSD with more (i.e. 07&nbsp;+&nbsp;12) data, we observe that SSD300 is already better than Faster R-CNN by 0.9&nbsp;% and that SSD512 is 3.6&nbsp;% better. If we take models trained on COCO <span class="u-monospace">trainval35k</span> as described in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec9">3.4</a> and fine-tuning them on the 07&nbsp;+&nbsp;12 dataset with SSD512, we achieve the best results: 81.5&nbsp;% mAP.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1. 
                  <b>PASCAL VOC2007 </b> <span class="u-monospace">test</span> <b> detection results.</b> Both Fast and Faster R-CNN use input images whose minimum dimension is 600. The two SSD models have exactly the same settings except that they have different input sizes (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-441" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-442"><span class="mn" id="MathJax-Span-443" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-444" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-445" style="font-family: MathJax_Main; padding-left: 0.201em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-41">300 \times 300</script></span> vs. <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-42-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-446" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-447"><span class="mn" id="MathJax-Span-448" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-449" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-450" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-42">512 \times 512</script></span>). It is obvious that larger input size leads to better results, and more data always helps. Data: “07”: VOC2007 <span class="u-monospace">trainval</span>, “07+12”: union of VOC2007 and VOC2012 <span class="u-monospace">trainval</span>. “07+12+COCO”: first train on COCO <span class="u-monospace">trainval35k</span> then fine-tune on 07+12.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<p>To understand the performance of our two SSD models in more details, we used the detection analysis tool from&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Hoiem, D., Chodpathumwan, Y., Dai, Q.: Diagnosing error in object detectors. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012. LNCS, vol. 7574, pp. 340–353. Springer, Heidelberg (2012). doi:
                    10.1007/978-3-642-33712-3_25
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR19" id="ref-link-section-d5248163e3130">19</a>]. Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig3">3</a> shows that SSD can detect various object categories with high quality (large white area). The majority of its confident detections are correct. The recall is around 85–90&nbsp;%, and is much higher with “weak” (0.1 Jaccard overlap) criteria. Compared to R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR20" id="ref-link-section-d5248163e3136">20</a>], SSD has less localization error, indicating that SSD can localize objects better because it directly learns to regress the object shape and classify object categories instead of using two decoupled steps. However, SSD has more confusions with similar object categories (especially for animals), partly because we share locations for multiple categories. Figure&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig4">4</a> shows that SSD is very sensitive to the bounding box size. In other words, it has much worse performance on smaller objects than bigger objects. This is not surprising because those small objects may not even have any information at the very top layers. Increasing the input size (e.g. from <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-43-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-451" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-452"><span class="mn" id="MathJax-Span-453" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-454" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-455" style="font-family: MathJax_Main; padding-left: 0.201em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-43">300 \times 300</script></span> to <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-44-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-456" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-457"><span class="mn" id="MathJax-Span-458" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-459" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-460" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-44">512 \times 512</script></span>) can help improve detecting small objects, but there is still a lot of room to improve. On the positive side, we can clearly see that SSD performs really well on large objects. And it is very robust to different object aspect ratios because we use default boxes of various aspect ratios per feature map location.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig3_HTML.gif?as=webp"><img aria-describedby="Fig3" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/419956_1_En_2_Fig3_HTML.gif" alt="figure 3" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>
                  <b>Visualization of performance for SSD 512 on animals, vehicles, and furniture from VOC2007 </b> <span class="u-monospace">test</span> <b> using</b>&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Hoiem, D., Chodpathumwan, Y., Dai, Q.: Diagnosing error in object detectors. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012. LNCS, vol. 7574, pp. 340–353. Springer, Heidelberg (2012). doi:
                    10.1007/978-3-642-33712-3_25
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR19" id="ref-link-section-d5248163e3214">19</a>]. The top row shows the cumulative fraction of detections that are correct (Cor) or false positive due to poor localization (Loc), confusion with similar categories (Sim), with others (Oth), or with background (BG). The bottom row shows the distribution of top-ranked false positive types.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig4_HTML.gif?as=webp"><img aria-describedby="Fig4" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/419956_1_En_2_Fig4_HTML.gif" alt="figure 4" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>
                  <b>Sensitivity and impact of different object characteristics on VOC2007 </b> <span class="u-monospace">test</span> <b> set using</b>&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Hoiem, D., Chodpathumwan, Y., Dai, Q.: Diagnosing error in object detectors. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012. LNCS, vol. 7574, pp. 340–353. Springer, Heidelberg (2012). doi:
                    10.1007/978-3-642-33712-3_25
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR19" id="ref-link-section-d5248163e3245">19</a>]. The plot on the left shows the effects of BBox Area per category, and the right plot shows the effect of Aspect Ratio.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec7"><span class="c-article-section__title-number">3.2 </span>Model Analysis</h3><p>To understand SSD better, we carried out controlled experiments to examine how each component affects performance. For all the experiments, we use the same settings and input size (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-45-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-461" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-462"><span class="mn" id="MathJax-Span-463" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-464" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-465" style="font-family: MathJax_Main; padding-left: 0.201em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-45">300 \times 300</script></span>), except for specified changes to the settings or component(s).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2. Effects of various design choices and components on SSD performance.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<p>
          <b>Data Augmentation is Crucial.</b> Fast and Faster R-CNN use the original image and the horizontal flip to train. We use a more extensive sampling strategy, similar to YOLO&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e3565">5</a>]. Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab2">2</a> shows that we can improve 8.8&nbsp;% mAP with this sampling strategy. We do not know how much our sampling strategy will benefit Fast and Faster R-CNN, but they are likely to benefit less because they use a feature pooling step during classification that is relatively robust to object translation by design.</p><p>
          <b>More Default Box Shapes is Better.</b> As described in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec4">2.2</a>, by default we use 6 default boxes per location. If we remove the boxes with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-46-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-466" style="width: 0.796em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1000.7em, 2.879em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-467"><span class="mfrac" id="MathJax-Span-468"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-469" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.35em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-470" style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>3</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-46">\frac{1}{3}</script></span> and 3 aspect ratios, the performance drops by 0.6&nbsp;%. By further removing the boxes with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-47-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-471" style="width: 0.796em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1000.7em, 2.879em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-472"><span class="mfrac" id="MathJax-Span-473"><span style="display: inline-block; position: relative; width: 0.499em; height: 0px; margin-right: 0.102em; margin-left: 0.102em;"><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -4.412em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-474" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.3em, 4.169em, -999.998em); top: -3.619em; left: 50%; margin-left: -0.196em;"><span class="mn" id="MathJax-Span-475" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; clip: rect(0.846em, 1000.5em, 1.193em, -999.998em); top: -1.238em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.499em; height: 0px; --darkreader-inline-border-top: initial;" data-darkreader-inline-border-top=""></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.503em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>2</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-47">\frac{1}{2}</script></span> and 2 aspect ratios, the performance drops another 2.1&nbsp;%. Using a variety of default box shapes seems to make the task of predicting boxes easier for the network.</p><p>
          <b>Atrous is Faster.</b> As described in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec5">3</a>, we used the atrous version of a subsampled VGG16, following DeepLab-LargeFOV&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Semantic image segmentation with deep convolutional nets and fully connected CRFs. In: ICLR (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR16" id="ref-link-section-d5248163e3637">16</a>]. If we use the full VGG16, keeping pool5 with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-48-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-476" style="width: 4.864em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.318em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.27em, 2.582em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-477"><span class="mn" id="MathJax-Span-478" style="font-family: MathJax_Main;">2</span><span class="mo" id="MathJax-Span-479" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-480" style="font-family: MathJax_Main; padding-left: 0.201em;">2</span><span class="mo" id="MathJax-Span-481" style="font-family: MathJax_Main; padding-left: 0.201em;">−</span><span class="mi" id="MathJax-Span-482" style="font-family: MathJax_Math-italic; padding-left: 0.201em;">s</span><span class="mn" id="MathJax-Span-483" style="font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.164em; border-left: 0px solid; width: 0px; height: 0.947em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mo>×</mo><mn>2</mn><mo>−</mo><mi>s</mi><mn>2</mn></math></span></span><script type="math/tex" id="MathJax-Element-48">2 \times 2-s2</script></span> and not subsampling parameters from fc6 and fc7, and add conv5_3 for prediction, the result is about the same while the speed is about 20&nbsp;% slower.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3. Effects of multiple layers.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<p>
          <b>Multiple Output Layers at Different Resolutions is Better.</b> A major contribution of SSD is using default boxes of different scales on different output layers. To measure the advantage gained, we progressively remove layers and compare results. For a fair comparison, every time we remove a layer, we adjust the default box tiling to keep the total number of boxes similar to the original (8732). This is done by stacking more scales of boxes on remaining layers and adjusting scales of boxes if needed. We do not exhaustively optimize the tiling for each setting. Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab3">3</a> shows a decrease in accuracy with fewer layers, dropping monotonically from 74.3 to 62.4. When we stack boxes of multiple scales on a layer, many are on the image boundary and need to be handled carefully. We tried the strategy used in Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e4036">2</a>], ignoring boxes which are on the boundary. We observe some interesting trends. For example, it hurts the performance by a large margin if we use very coarse feature maps (e.g. conv11_2 (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-49-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-484" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-485"><span class="mn" id="MathJax-Span-486" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-487" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-488" style="font-family: MathJax_Main; padding-left: 0.201em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.836em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>×</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-49">1 \times 1</script></span>) or conv10_2 (<span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-50-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-489" style="width: 2.483em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.185em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1002.13em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-490"><span class="mn" id="MathJax-Span-491" style="font-family: MathJax_Main;">3</span><span class="mo" id="MathJax-Span-492" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-493" style="font-family: MathJax_Main; padding-left: 0.201em;">3</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo><mn>3</mn></math></span></span><script type="math/tex" id="MathJax-Element-50">3\times 3</script></span>)). The reason might be that we do not have enough large boxes to cover large objects after the pruning. When we use primarily finer resolution maps, the performance starts increasing again because even after pruning a sufficient number of large boxes remains. If we only use conv7 for prediction, the performance is the worst, reinforcing the message that it is critical to spread boxes of different scales over different layers.</p><h3 class="c-article__sub-heading" id="Sec8"><span class="c-article-section__title-number">3.3 </span>PASCAL VOC2012</h3><p>We use the same settings as those used for our basic VOC2007 experiments above, except that we use VOC2012 <span class="u-monospace">trainval</span> and VOC2007 <span class="u-monospace">trainval</span> and <span class="u-monospace">test</span> (21503 images) for training, and test on VOC2012 <span class="u-monospace">test</span> (10991 images). We train the models with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-51-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-494" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-495"><span class="msubsup" id="MathJax-Span-496"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-497" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-498"><span class="mrow" id="MathJax-Span-499"><span class="mo" id="MathJax-Span-500" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-501" style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>3</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-51">10^{-3}</script></span> learning rate for 60k iterations, then <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-52-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-502" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-503"><span class="msubsup" id="MathJax-Span-504"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-505" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-506"><span class="mrow" id="MathJax-Span-507"><span class="mo" id="MathJax-Span-508" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-509" style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-52">10^{-4}</script></span> for 20k iterations. Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab4">4</a> shows the results of our SSD300 and SSD512<sup><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> model. We see the same performance trend as we observed on VOC2007 test. Our SSD300 improves accuracy over Fast/Faster R-CNN. By increasing the training and testing image size to <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-53-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-510" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-511"><span class="mn" id="MathJax-Span-512" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-513" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-514" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-53">512\times 512</script></span>, we are 4.5&nbsp;% more accurate than Faster R-CNN. Compared to YOLO, SSD is significantly more accurate, likely due to the use of convolutional default boxes from multiple feature maps and our matching strategy during training. When fine-tuned from models trained on COCO, our SSD512 achieves 80.0&nbsp;% mAP, which is 4.1&nbsp;% higher than Faster R-CNN.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4. 
                  <b>PASCAL VOC2012 </b> <span class="u-monospace">test</span> <b> detection results.</b> Fast and Faster R-CNN use images with minimum dimension 600, while the image size for YOLO is <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-54-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;448&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;448&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-515" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.491em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-516"><span class="mn" id="MathJax-Span-517" style="font-family: MathJax_Main;">448</span><span class="mo" id="MathJax-Span-518" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-519" style="font-family: MathJax_Main; padding-left: 0.201em;">448</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>448</mn><mo>×</mo><mn>448</mn></math></span></span><script type="math/tex" id="MathJax-Element-54">448 \times 448</script></span>. data: “07++12”: union of VOC2007 <span class="u-monospace">trainval</span> and <span class="u-monospace">test</span> and VOC2012 <span class="u-monospace">trainval</span>. “07++12+COCO”: first train on COCO <span class="u-monospace">trainval35k</span> then fine-tune on 07++12.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec9"><span class="c-article-section__title-number">3.4 </span>COCO</h3><p>To further validate the SSD framework, we trained our SSD300 and SSD512 architectures on the COCO dataset. Since objects in COCO tend to be smaller than PASCAL VOC, we use smaller default boxes for all layers. We follow the strategy mentioned in Sect.&nbsp;<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec4">2.2</a>, but now our smallest default box has a scale of 0.15 instead of 0.2, and the scale of the default box on conv4_3 is 0.07 (e.g. 21 pixels for a <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-55-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;300&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-520" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-521"><span class="mn" id="MathJax-Span-522" style="font-family: MathJax_Main;">300</span><span class="mo" id="MathJax-Span-523" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-524" style="font-family: MathJax_Main; padding-left: 0.201em;">300</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>300</mn><mo>×</mo><mn>300</mn></math></span></span><script type="math/tex" id="MathJax-Element-55">300 \times 300</script></span> image).</p><p>We use the <span class="u-monospace">trainval35k</span>&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bell, S., Zitnick, C.L., Bala, K., Girshick, R.: Inside-outside net: detecting objects in context with skip pooling and recurrent neural networks. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR21" id="ref-link-section-d5248163e4330">21</a>] for training. We first train the model with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-56-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-525" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-526"><span class="msubsup" id="MathJax-Span-527"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-528" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-529"><span class="mrow" id="MathJax-Span-530"><span class="mo" id="MathJax-Span-531" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-532" style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>3</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-56">10^{-3}</script></span> learning rate for 160k iterations, and then continue training for 40k iterations with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-57-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-533" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-534"><span class="msubsup" id="MathJax-Span-535"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-536" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-537"><span class="mrow" id="MathJax-Span-538"><span class="mo" id="MathJax-Span-539" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-540" style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-57">10^{-4}</script></span> and 40k iterations with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-58-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-541" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-542"><span class="msubsup" id="MathJax-Span-543"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-544" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-545"><span class="mrow" id="MathJax-Span-546"><span class="mo" id="MathJax-Span-547" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-548" style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>5</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-58">10^{-5}</script></span>. Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab5">5</a> shows the results on <span class="u-monospace">test-dev2015</span>. Similar to what we observed on the PASCAL VOC dataset, SSD300 is better than Fast R-CNN in both mAP@0.5 and mAP@[0.5:0.95]. SSD300 has a similar mAP@[0.5:0.95] to Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="COCO:Common Objects in Context (2016). 
                    http://mscoco.org/dataset/#detections-leaderboard
                    
                  . Accessed 25 July 2016" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR22" id="ref-link-section-d5248163e4427">22</a>]. However, the mAP@0.5 is worse and we conjecture that it is because the image size is too small, which prevents the model from detecting many small objects. But overall, SSD can localize objects more accurately. By increasing the image size to <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-59-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;512&lt;/mn&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-549" style="width: 4.665em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1004.12em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-550"><span class="mn" id="MathJax-Span-551" style="font-family: MathJax_Main;">512</span><span class="mo" id="MathJax-Span-552" style="font-family: MathJax_Main; padding-left: 0.201em;">×</span><span class="mn" id="MathJax-Span-553" style="font-family: MathJax_Main; padding-left: 0.201em;">512</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>512</mn><mo>×</mo><mn>512</mn></math></span></span><script type="math/tex" id="MathJax-Element-59">512 \times 512</script></span>, our SSD512 is better than Faster R-CNN in both criteria. In addition, our SSD512 model is also better than ION&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bell, S., Zitnick, C.L., Bala, K., Girshick, R.: Inside-outside net: detecting objects in context with skip pooling and recurrent neural networks. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR21" id="ref-link-section-d5248163e4456">21</a>], a multi-scale version of Fast R-CNN with explicit modeling of context using a recurrent network. In Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig5">5</a>, we show some detection examples on COCO <span class="u-monospace">test-dev</span> with the SSD512 model.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5. COCO <span class="u-monospace">test-dev2015</span> detection results.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec10"><span class="c-article-section__title-number">3.5 </span>Preliminary ILSVRC Results</h3><p>We applied the same network architecture we used for COCO to the ILSVRC DET dataset&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: Imagenet large scale visual recognition challenge. IJCV 115, 211 (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR15" id="ref-link-section-d5248163e4808">15</a>]. We train a SSD300 model using the ILSVRC2014 DET <span class="u-monospace">train</span> and <span class="u-monospace">val1</span> as used in&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR20" id="ref-link-section-d5248163e4817">20</a>]. We first train the model with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-60-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-554" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-555"><span class="msubsup" id="MathJax-Span-556"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-557" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-558"><span class="mrow" id="MathJax-Span-559"><span class="mo" id="MathJax-Span-560" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-561" style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>3</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-60">10^{-3}</script></span> learning rate for 320k iterations, and then continue training for 80k iterations with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-61-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-562" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.292em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-563"><span class="msubsup" id="MathJax-Span-564"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-565" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-566"><span class="mrow" id="MathJax-Span-567"><span class="mo" id="MathJax-Span-568" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-569" style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-61">10^{-4}</script></span> and 40k iterations with <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-62-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-570" style="width: 2.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.342em, 1001.99em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-571"><span class="msubsup" id="MathJax-Span-572"><span style="display: inline-block; position: relative; width: 1.987em; height: 0px;"><span style="position: absolute; clip: rect(3.227em, 1000.95em, 4.169em, -999.998em); top: -4.015em; left: 0em;"><span class="mn" id="MathJax-Span-573" style="font-family: MathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span><span style="position: absolute; top: -4.412em; left: 0.995em;"><span class="texatom" id="MathJax-Span-574"><span class="mrow" id="MathJax-Span-575"><span class="mo" id="MathJax-Span-576" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-577" style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span style="display: inline-block; width: 0px; height: 4.02em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mo>−</mo><mn>5</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-62">10^{-5}</script></span>. We can achieve 43.2&nbsp;mAP on the <span class="u-monospace">val2</span> set&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR20" id="ref-link-section-d5248163e4911">20</a>]. Again, it validates that SSD is a general framework for high quality real-time detection.</p><h3 class="c-article__sub-heading" id="Sec11"><span class="c-article-section__title-number">3.6 </span>Inference Time</h3><p>Considering the large number of boxes generated from our method, it is essential to perform non-maximum suppression (nms) efficiently during inference. By using a confidence threshold of 0.01, we can filter out most boxes. We then apply nms with Jaccard overlap of 0.45 per class and keep the top 200 detections per image. This step costs about 1.7&nbsp;ms per image for SSD300 and 20 VOC classes, which is close to the total time (2.4&nbsp;ms) spent on all newly added layers.</p><p>Table&nbsp;<a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Tab6">6</a> shows the comparison between SSD, Faster R-CNN [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e4928">2</a>], and YOLO [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e4931">5</a>]. Both our SSD300 and SSD512 method outperforms Faster R-CNN in both speed and accuracy. Although Fast YOLO [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e4934">5</a>] can run at 155&nbsp;FPS, it has lower accuracy by almost 22&nbsp;% mAP. To the best of our knowledge, SSD300 is the first real-time method to achieve above 70&nbsp;% mAP. Note that about 80&nbsp;% of the forward time is spent on the base network (VGG16 in our case). Therefore, using a faster base network could further improve the speed, making the SSD512 model real-time as well.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6. 
                  <b>Results on Pascal VOC2007 </b> <span class="u-monospace">test.</span> SSD300 is the only real-time detection method that can achieve above 70&nbsp;% mAP. By using a larger input image, SSD512 outperforms all methods on accuracy while maintaining a close to real-time speed. Using a test batch size of 8 improves the speed further.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/tables/6" aria-label="Full size table 6"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section data-title="Related Work"><div class="c-article-section" id="Sec12-section"><h2 id="Sec12" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">4 </span>Related Work</h2><div class="c-article-section__content" id="Sec12-content"><p>There are two established classes of methods for object detection in images, one based on sliding windows and the other based on region proposal classification. Before the advent of convolutional neural networks, the state of the art for those two approaches – Deformable Part Model (DPM)&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Felzenszwalb, P., McAllester, D., Ramanan, D.: A discriminatively trained, multiscale, deformable part model. In: CVPR (2008)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR23" id="ref-link-section-d5248163e5259">23</a>] and Selective Search&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W.: Selective search for object recognition. IJCV 104, 154 (2013)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR1" id="ref-link-section-d5248163e5262">1</a>] – had comparable performance. However, after the dramatic improvement brought on by R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR20" id="ref-link-section-d5248163e5265">20</a>], which combines selective search region proposals and convolutional network based post-classification, region proposal object detection methods became prevalent.</p><p>The original R-CNN approach has been improved in a variety of ways. The first set of approaches improve the quality and speed of post-classification, since it requires the classification of thousands of image crops, which is expensive and time-consuming. SPPnet&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="He, K., Zhang, X., Ren, S., Sun, J.: Spatial pyramid pooling in deep convolutional networks for visual recognition. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8691, pp. 346–361. Springer, Heidelberg (2014). doi:
                    10.1007/978-3-319-10578-9_23
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR9" id="ref-link-section-d5248163e5271">9</a>] speeds up the original R-CNN approach significantly. It introduces a spatial pyramid pooling layer that is more robust to region size and scale and allows the classification layers to reuse features computed over feature maps generated at several image resolutions. Fast R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Girshick, R.: Fast R-CNN. In: ICCV (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR6" id="ref-link-section-d5248163e5274">6</a>] extends SPPnet so that it can fine-tune all layers end-to-end by minimizing a loss for both confidences and bounding box regression, which was first introduced in MultiBox&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e5277">7</a>] for learning objectness.</p><p>The second set of approaches improve the quality of proposal generation using deep neural networks. In the most recent works like MultiBox&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e5283">7</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Szegedy, C., Reed, S., Erhan, D., Anguelov, D.: Scalable, high-quality object detection. arXiv preprint v3 (2015). 
                    arXiv:1412.1441
                    
                  
        " href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR8" id="ref-link-section-d5248163e5286">8</a>], the Selective Search region proposals, which are based on low-level image features, are replaced by proposals generated directly from a separate deep neural network. This further improves the detection accuracy but results in a somewhat complex setup, requiring the training of two neural networks with a dependency between them. Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e5289">2</a>] replaces selective search proposals by ones learned from a region proposal network (RPN), and introduces a method to integrate the RPN with Fast R-CNN by alternating between fine-tuning shared convolutional layers and prediction layers for these two networks. This way region proposals are used to pool mid-level features and the final classification step is less expensive. Our SSD is very similar to the region proposal network (RPN) in Faster R-CNN in that we also use a fixed set of (default) boxes for prediction, similar to the achor boxes in the RPN. But instead of using these to pool features and evaluate another classifier, we simultaneously produce a score for each object category in each box. Thus, our approach avoids the complication of merging RPN with Fast R-CNN and is easier to train, faster, and straightforward to integrate in other tasks.</p><p>Another set of methods, which are directly related to our approach, skip the proposal step altogether and predict bounding boxes and confidences for multiple categories directly. OverFeat&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR4" id="ref-link-section-d5248163e5295">4</a>], a deep version of the sliding window method, predicts a bounding box directly from each location of the topmost feature map after knowing the confidences of the underlying object categories. YOLO&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e5298">5</a>] uses the whole topmost feature map to predict both confidences for multiple categories and bounding boxes (which are shared for these categories). Our SSD method falls in this category because we do not have the proposal step but use the default boxes. However, our approach is more flexible than the existing methods because we can use default boxes of different aspect ratios on each feature location from multiple feature maps at different scales. If we only use one default box per location from the topmost feature map, our SSD would have similar architecture to OverFeat&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR4" id="ref-link-section-d5248163e5301">4</a>]; if we use the whole topmost feature map and add a fully connected layer for predictions instead of our convolutional predictors, and do not explicitly consider multiple aspect ratios, we can approximately reproduce YOLO&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e5304">5</a>].</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig5_HTML.gif?as=webp"><img aria-describedby="Fig5" src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/419956_1_En_2_Fig5_HTML.gif" alt="figure 5" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>
                <b>Detection examples on COCO </b> <span class="u-monospace">test-dev</span> <b> with SSD512 model.</b> We show detections with scores higher than 0.6. Each color corresponds to an object category.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div>
</div></div></section><section data-title="Conclusions"><div class="c-article-section" id="Sec13-section"><h2 id="Sec13" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">5 </span>Conclusions</h2><div class="c-article-section__content" id="Sec13-content"><p>This paper introduces SSD, a fast single-shot object detector for multiple categories. A key feature of our model is the use of multi-scale convolutional bounding box outputs attached to multiple feature maps at the top of the network. This representation allows us to efficiently model the space of possible box shapes. We experimentally validate that given appropriate training strategies, a larger number of carefully chosen default bounding boxes results in improved performance. We build SSD models with at least an order of magnitude more box predictions sampling location, scale, and aspect ratio, than existing methods&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e5343">5</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR7" id="ref-link-section-d5248163e5346">7</a>].</p><p>We demonstrate that given the same VGG-16 base architecture, SSD compares favorably to its state-of-the-art object detector counterparts in terms of both accuracy and speed. Our SSD512 model significantly outperforms the state-of-the-art Faster R-CNN&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR2" id="ref-link-section-d5248163e5352">2</a>] in terms of accuracy on PASCAL VOC and COCO, while being <span class="mathjax-tex"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-63-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-578" style="width: 1.441em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.292em; height: 0px; font-size: 112%;"><span style="position: absolute; clip: rect(1.54em, 1001.14em, 2.483em, -999.998em); top: -2.329em; left: 0em;"><span class="mrow" id="MathJax-Span-579"><span class="mn" id="MathJax-Span-580" style="font-family: MathJax_Main;">3</span><span class="mo" id="MathJax-Span-581" style="font-family: MathJax_Main;">×</span></span><span style="display: inline-block; width: 0px; height: 2.334em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-left=""></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo></math></span></span><script type="math/tex" id="MathJax-Element-63">3 \times </script></span> faster. Our real time SSD300 model runs at 59&nbsp;FPS, which is faster than the current real time YOLO&nbsp;[<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#ref-CR5" id="ref-link-section-d5248163e5379">5</a>] alternative, while producing markedly superior detection accuracy.</p><p>Apart from its standalone utility, we believe that our monolithic and relatively simple SSD model provides a useful building block for larger systems that employ an object detection component. A promising future direction is to explore its use as part of a system using recurrent neural networks to detect and track objects in video simultaneously.</p></div></div></section>
                        </div>
                    
                

                <section data-title="Notes" lang="en"><div class="c-article-section" id="notes-section"><h2 id="notes" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>We use the VGG-16 network as a base, but other networks should also produce good results.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>For SSD512 model, we add extra conv12_2 for prediction.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>
                        <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=4.">http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=</a>
                        <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=4.">mean&amp;challengeid=11&amp;compid=4.</a>
                      </p></div></li></ol></div></div></section><div id="MagazineFulltextChapterBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 id="Bib1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W.: Selective search for object recognition. IJCV <b>104</b>, 154 (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR1-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s11263-013-0620-5" data-track-action="CrossRef reference" href="https://doi.org/10.1007%2Fs11263-013-0620-5" aria-label="CrossRef reference 1" data-doi="10.1007/s11263-013-0620-5">CrossRef</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="https://scholar.google.com/scholar_lookup?&amp;title=Selective%20search%20for%20object%20recognition&amp;journal=IJCV&amp;volume=104&amp;publication_year=2013&amp;author=Uijlings%2CJR&amp;author=Sande%2CKE&amp;author=Gevers%2CT&amp;author=Smeulders%2CAW">
                    Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR2-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Ren%2C%20S.%2C%20He%2C%20K.%2C%20Girshick%2C%20R.%2C%20Sun%2C%20J.%3A%20Faster%20R-CNN%3A%20towards%20real-time%20object%20detection%20with%20region%20proposal%20networks.%20In%3A%20NIPS%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR3-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=He%2C%20K.%2C%20Zhang%2C%20X.%2C%20Ren%2C%20S.%2C%20Sun%2C%20J.%3A%20Deep%20residual%20learning%20for%20image%20recognition.%20In%3A%20CVPR%20%282016%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR4-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Sermanet%2C%20P.%2C%20Eigen%2C%20D.%2C%20Zhang%2C%20X.%2C%20Mathieu%2C%20M.%2C%20Fergus%2C%20R.%2C%20LeCun%2C%20Y.%3A%20Overfeat%3A%20integrated%20recognition%2C%20localization%20and%20detection%20using%20convolutional%20networks.%20In%3A%20ICLR%20%282014%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR5-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Redmon%2C%20J.%2C%20Divvala%2C%20S.%2C%20Girshick%2C%20R.%2C%20Farhadi%2C%20A.%3A%20You%20only%20look%20once%3A%20unified%2C%20real-time%20object%20detection.%20In%3A%20CVPR%20%282016%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Girshick, R.: Fast R-CNN. In: ICCV (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR6-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Girshick%2C%20R.%3A%20Fast%20R-CNN.%20In%3A%20ICCV%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR7-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Erhan%2C%20D.%2C%20Szegedy%2C%20C.%2C%20Toshev%2C%20A.%2C%20Anguelov%2C%20D.%3A%20Scalable%20object%20detection%20using%20deep%20neural%20networks.%20In%3A%20CVPR%20%282014%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Szegedy, C., Reed, S., Erhan, D., Anguelov, D.: Scalable, high-quality object detection. arXiv preprint v3 (2015). <a href="http://arxiv.org/abs/1412.1441">arXiv:1412.1441</a>
        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">He, K., Zhang, X., Ren, S., Sun, J.: Spatial pyramid pooling in deep convolutional networks for visual recognition. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8691, pp. 346–361. Springer, Heidelberg (2014). doi:<a href="https://doi.org/10.1007/978-3-319-10578-9_23">10.1007/978-3-319-10578-9_23</a>
        </p><p class="c-article-references__links u-hide-print" id="ref-CR9-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="https://scholar.google.com/scholar_lookup?&amp;title=Spatial%20pyramid%20pooling%20in%20deep%20convolutional%20networks%20for%20visual%20recognition&amp;pages=346-361&amp;publication_year=2014&amp;author=He%2CK&amp;author=Zhang%2CX&amp;author=Ren%2CS&amp;author=Sun%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: CVPR (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR10-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Long%2C%20J.%2C%20Shelhamer%2C%20E.%2C%20Darrell%2C%20T.%3A%20Fully%20convolutional%20networks%20for%20semantic%20segmentation.%20In%3A%20CVPR%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Hariharan, B., Arbeláez, P., Girshick, R., Malik, J.: Hypercolumns for object segmentation and fine-grained localization. In: CVPR (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR11-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Hariharan%2C%20B.%2C%20Arbel%C3%A1ez%2C%20P.%2C%20Girshick%2C%20R.%2C%20Malik%2C%20J.%3A%20Hypercolumns%20for%20object%20segmentation%20and%20fine-grained%20localization.%20In%3A%20CVPR%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Liu, W., Rabinovich, A., Berg, A.C.: ParseNet: looking wider to see better. In: ILCR (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR12-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Liu%2C%20W.%2C%20Rabinovich%2C%20A.%2C%20Berg%2C%20A.C.%3A%20ParseNet%3A%20looking%20wider%20to%20see%20better.%20In%3A%20ILCR%20%282016%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Howard, A.G.: Some improvements on deep convolutional neural network based image classification. arXiv preprint (2013). <a href="http://arxiv.org/abs/1312.5402">arXiv:1312.5402</a>
        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. In: NIPS (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR14-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Simonyan%2C%20K.%2C%20Zisserman%2C%20A.%3A%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition.%20In%3A%20NIPS%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: Imagenet large scale visual recognition challenge. IJCV <b>115</b>, 211 (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR15-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s11263-015-0816-y" data-track-action="CrossRef reference" href="https://doi.org/10.1007%2Fs11263-015-0816-y" aria-label="CrossRef reference 15" data-doi="10.1007/s11263-015-0816-y">CrossRef</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="MathSciNet reference" href="http://www.ams.org/mathscinet-getitem?mr=3422482" aria-label="MathSciNet reference 15">MathSciNet</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="https://scholar.google.com/scholar_lookup?&amp;title=Imagenet%20large%20scale%20visual%20recognition%20challenge&amp;journal=IJCV&amp;volume=115&amp;publication_year=2015&amp;author=Russakovsky%2CO&amp;author=Deng%2CJ&amp;author=Su%2CH&amp;author=Krause%2CJ&amp;author=Satheesh%2CS&amp;author=Ma%2CS&amp;author=Huang%2CZ&amp;author=Karpathy%2CA&amp;author=Khosla%2CA&amp;author=Bernstein%2CM&amp;author=Berg%2CAC&amp;author=Fei-Fei%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Semantic image segmentation with deep convolutional nets and fully connected CRFs. In: ICLR (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR16-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Chen%2C%20L.C.%2C%20Papandreou%2C%20G.%2C%20Kokkinos%2C%20I.%2C%20Murphy%2C%20K.%2C%20Yuille%2C%20A.L.%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%20and%20fully%20connected%20CRFs.%20In%3A%20ICLR%20%282015%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: convolutional architecture for fast feature embedding. In: MM. ACM (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR17-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Jia%2C%20Y.%2C%20Shelhamer%2C%20E.%2C%20Donahue%2C%20J.%2C%20Karayev%2C%20S.%2C%20Long%2C%20J.%2C%20Girshick%2C%20R.%2C%20Guadarrama%2C%20S.%2C%20Darrell%2C%20T.%3A%20Caffe%3A%20convolutional%20architecture%20for%20fast%20feature%20embedding.%20In%3A%20MM.%20ACM%20%282014%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Glorot, X., Bengio, Y.: Understanding the difficulty of training deep feedforward neural networks. In: AISTATS (2010)</p><p class="c-article-references__links u-hide-print" id="ref-CR18-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Glorot%2C%20X.%2C%20Bengio%2C%20Y.%3A%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks.%20In%3A%20AISTATS%20%282010%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Hoiem, D., Chodpathumwan, Y., Dai, Q.: Diagnosing error in object detectors. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012. LNCS, vol. 7574, pp. 340–353. Springer, Heidelberg (2012). doi:<a href="https://doi.org/10.1007/978-3-642-33712-3_25">10.1007/978-3-642-33712-3_25</a>
        </p><p class="c-article-references__links u-hide-print" id="ref-CR19-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="https://scholar.google.com/scholar_lookup?&amp;title=Diagnosing%20error%20in%20object%20detectors&amp;pages=340-353&amp;publication_year=2012&amp;author=Hoiem%2CD&amp;author=Chodpathumwan%2CY&amp;author=Dai%2CQ">
                    Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR20-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Girshick%2C%20R.%2C%20Donahue%2C%20J.%2C%20Darrell%2C%20T.%2C%20Malik%2C%20J.%3A%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation.%20In%3A%20CVPR%20%282014%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Bell, S., Zitnick, C.L., Bala, K., Girshick, R.: Inside-outside net: detecting objects in context with skip pooling and recurrent neural networks. In: CVPR (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR21-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Bell%2C%20S.%2C%20Zitnick%2C%20C.L.%2C%20Bala%2C%20K.%2C%20Girshick%2C%20R.%3A%20Inside-outside%20net%3A%20detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks.%20In%3A%20CVPR%20%282016%29">
                        Google Scholar</a>&nbsp;
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">COCO:Common Objects in Context (2016). <a href="http://mscoco.org/dataset/%23detections-leaderboard">http://mscoco.org/dataset/#detections-leaderboard</a>. Accessed 25 July 2016</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Felzenszwalb, P., McAllester, D., Ramanan, D.: A discriminatively trained, multiscale, deformable part model. In: CVPR (2008)</p><p class="c-article-references__links u-hide-print" id="ref-CR23-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Felzenszwalb%2C%20P.%2C%20McAllester%2C%20D.%2C%20Ramanan%2C%20D.%3A%20A%20discriminatively%20trained%2C%20multiscale%2C%20deformable%20part%20model.%20In%3A%20CVPR%20%282008%29">
                        Google Scholar</a>&nbsp;
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/978-3-319-46448-0_2?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgment" lang="en"><div class="c-article-section" id="Ack1-section"><h2 id="Ack1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Acknowledgment</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was started as an internship project at Google and continued at UNC. We would like to thank Alex Toshev for helpful discussions and are indebted to the Image Understanding and DistBelief teams at Google. We also thank Philip Ammirato and Patrick Poirson for helpful comments. We thank NVIDIA for providing GPUs and acknowledge support from NSF 1452851, 1446631, 1526367, 1533771.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 id="author-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff17"><p class="c-article-author-affiliation__address">UNC Chapel Hill, Chapel Hill, USA</p><p class="c-article-author-affiliation__authors-list">Wei Liu,&nbsp;Cheng-Yang Fu&nbsp;&amp;&nbsp;Alexander C. Berg</p></li><li id="Aff18"><p class="c-article-author-affiliation__address">Zoox Inc., Palo Alto, USA</p><p class="c-article-author-affiliation__authors-list">Dragomir Anguelov</p></li><li id="Aff19"><p class="c-article-author-affiliation__address">Google Inc., Mountain View, USA</p><p class="c-article-author-affiliation__authors-list">Dumitru Erhan&nbsp;&amp;&nbsp;Christian Szegedy</p></li><li id="Aff20"><p class="c-article-author-affiliation__address">University of Michigan, Ann-Arbor, USA</p><p class="c-article-author-affiliation__authors-list">Scott Reed</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Wei-Liu"><span class="c-article-authors-search__title u-h3 js-search-name">Wei Liu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Wei%20Liu" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wei%20Liu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wei%20Liu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Dragomir-Anguelov"><span class="c-article-authors-search__title u-h3 js-search-name">Dragomir Anguelov</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Dragomir%20Anguelov" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Dragomir%20Anguelov" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Dragomir%20Anguelov%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Dumitru-Erhan"><span class="c-article-authors-search__title u-h3 js-search-name">Dumitru Erhan</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Dumitru%20Erhan" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Dumitru%20Erhan" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Dumitru%20Erhan%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Christian-Szegedy"><span class="c-article-authors-search__title u-h3 js-search-name">Christian Szegedy</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Christian%20Szegedy" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Christian%20Szegedy" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Christian%20Szegedy%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Scott-Reed"><span class="c-article-authors-search__title u-h3 js-search-name">Scott Reed</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Scott%20Reed" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Scott%20Reed" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Scott%20Reed%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Cheng_Yang-Fu"><span class="c-article-authors-search__title u-h3 js-search-name">Cheng-Yang Fu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Cheng-Yang%20Fu" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Cheng-Yang%20Fu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Cheng-Yang%20Fu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Alexander_C_-Berg"><span class="c-article-authors-search__title u-h3 js-search-name">Alexander C. Berg</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="https://link.springer.com/search?dc.creator=Alexander%20C.%20Berg" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alexander%20C.%20Berg" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">&nbsp;</span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alexander%20C.%20Berg%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:wliu@cs.unc.edu">Wei Liu </a>.</p></div></div></section><section aria-labelledby="editor-information" data-title="Editor information"><div class="c-article-section" id="editor-information-section"><h2 id="editor-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Editor information</h2><div class="c-article-section__content" id="editor-information-content"><h3 class="c-article__sub-heading" id="editor-affiliations">Editors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff13"><p class="c-article-author-affiliation__address">RWTH Aachen , Aachen, Germany</p><p class="c-article-author-affiliation__authors-list">Bastian Leibe</p></li><li id="Aff14"><p class="c-article-author-affiliation__address">Czech Technical University , Prague 2, Czech Republic</p><p class="c-article-author-affiliation__authors-list">Jiri Matas</p></li><li id="Aff15"><p class="c-article-author-affiliation__address">University of Trento , Povo - Trento, Italy</p><p class="c-article-author-affiliation__authors-list">Nicu Sebe</p></li><li id="Aff16"><p class="c-article-author-affiliation__address">University of Amsterdam , Amsterdam, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Max Welling</p></li></ol></div></div></section><section data-title="Rights and permissions" lang="en"><div class="c-article-section" id="rightslink-section"><h2 id="rightslink" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights" data-test="rightslink-content"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?publisherName=SpringerNature&amp;orderBeanReset=true&amp;orderSource=SpringerLink&amp;title=SSD%3A%20Single%20Shot%20MultiBox%20Detector&amp;author=Wei%20Liu%2C%20Dragomir%20Anguelov%2C%20Dumitru%20Erhan%20et%20al&amp;contentID=10.1007%2F978-3-319-46448-0_2&amp;copyright=Springer%20International%20Publishing%20AG&amp;publication=eBook&amp;publicationDate=2016&amp;startPage=21&amp;endPage=37&amp;imprint=Springer%20International%20Publishing%20AG">Reprints and Permissions</a></p></div></div></section><section data-title="Copyright information"><div class="c-article-section" id="copyright-information-section"><h2 id="copyright-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Copyright information</h2><div class="c-article-section__content" id="copyright-information-content"><p>© 2016 Springer International Publishing AG</p></div></div></section><section aria-labelledby="chapter-info" data-title="About this paper" lang="en"><div class="c-article-section" id="chapter-info-section"><h2 id="chapter-info" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>About this paper</h2><div class="c-article-section__content" id="chapter-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas" tabindex="-1">Cite this paper</h3><p class="c-bibliographic-information__citation" data-test="bibliographic-information__cite_this_chapter">Liu, W. <i>et al.</i> (2016).  SSD: Single Shot MultiBox Detector.

                     In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds) Computer Vision – ECCV 2016. ECCV 2016. Lecture Notes in Computer Science(), vol 9905. Springer, Cham. https://doi.org/10.1007/978-3-319-46448-0_2</p><h3 class="c-bibliographic-information__download-citation u-mb-8 u-mt-16 u-hide-print">Download citation</h3><ul class="c-bibliographic-information__download-citation-list"><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article&#39;s citation as a .RIS file" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/978-3-319-46448-0_2?format=refman&amp;flavour=citation">.RIS<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></li><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article&#39;s citation as a .ENW file" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/978-3-319-46448-0_2?format=endnote&amp;flavour=citation">.ENW<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></li><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article&#39;s citation as a .BIB file" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/978-3-319-46448-0_2?format=bibtex&amp;flavour=citation">.BIB<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></li></ul><ul class="c-bibliographic-information__list u-mb-24" data-test="publication-history"><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p data-test="bibliographic-information__doi"><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/978-3-319-46448-0_2</span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-09-17">17 September 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__publisher-name">
                            Publisher Name<span class="u-hide">: </span><span class="c-bibliographic-information__value">Springer, Cham</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__pisbn">
                                Print ISBN<span class="u-hide">: </span><span class="c-bibliographic-information__value">978-3-319-46447-3</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__eisbn">
                                Online ISBN<span class="u-hide">: </span><span class="c-bibliographic-information__value">978-3-319-46448-0</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__package">eBook Packages<span class="u-hide">: </span><span class="c-bibliographic-information__multi-value"><a href="https://link.springer.com/search?facet-content-type=%22Book%22&amp;package=11645&amp;facet-start-year=2016&amp;facet-end-year=2016">Computer Science</a></span><span class="c-bibliographic-information__multi-value"><a href="https://link.springer.com/search?facet-content-type=%22Book%22&amp;package=43710&amp;facet-start-year=2016&amp;facet-end-year=2016">Computer Science (R0)</a></span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-block"><h3 class="c-article__sub-heading">Share this paper</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                                Provided by the Springer Nature SharedIt content-sharing initiative
                            </p></div></div><div data-component="chapter-info-list"></div></div></div></div></div></section>
                
                
    

            </div>
        </article>
    </main>

    <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="conference paper">
        <aside>
            
            <div data-test="download-article-link-wrapper" class="js-context-bar-sticky-point-desktop">
                
            </div>

            <div data-test="editorial-summary">
                
            </div>

            <div class="c-reading-companion">
                <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky" style="top: 40px; width: 321.047px;">

                    

                    <ul class="c-reading-companion__tabs" role="tablist"><li role="presentation"><button data-tab-target="sections" role="tab" id="tab-sections" aria-controls="tabpanel-sections" aria-selected="true" class="c-reading-companion__tab c-reading-companion__tab--active" data-track="click" data-track-action="sections tab" data-track-label="tab">Sections</button></li><li role="presentation"><button data-tab-target="figures" role="tab" id="tab-figures" aria-controls="tabpanel-figures" aria-selected="false" tabindex="-1" class="c-reading-companion__tab" data-track="click" data-track-action="figures tab" data-track-label="tab">Figures</button></li><li role="presentation"><button data-tab-target="references" role="tab" id="tab-references" aria-controls="tabpanel-references" aria-selected="false" tabindex="-1" class="c-reading-companion__tab" data-track="click" data-track-action="references tab" data-track-label="tab">References</button></li></ul><div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections" aria-labelledby="tab-sections" role="tabpanel"><div class="c-reading-companion__scroll-pane" style="max-height: 775.5px;"><ul class="c-reading-companion__sections-list"><li id="rc-sec-Abs1" class="c-reading-companion__section-item c-reading-companion__section-item--active"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Abs1" data-track="click" data-track-action="section anchor" data-track-label="link: Abstract"><span class="c-article-section__title-number"> </span>Abstract</a></li><li id="rc-sec-Sec1" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec1" data-track="click" data-track-action="section anchor" data-track-label="link: Introduction"><span class="c-article-section__title-number">1 </span>Introduction</a></li><li id="rc-sec-Sec2" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec2" data-track="click" data-track-action="section anchor" data-track-label="link: The Single Shot Detector SSD"><span class="c-article-section__title-number">2 </span>The Single Shot Detector (SSD)</a></li><li id="rc-sec-Sec5" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec5" data-track="click" data-track-action="section anchor" data-track-label="link: Experimental Results"><span class="c-article-section__title-number">3 </span>Experimental Results</a></li><li id="rc-sec-Sec12" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec12" data-track="click" data-track-action="section anchor" data-track-label="link: Related Work"><span class="c-article-section__title-number">4 </span>Related Work</a></li><li id="rc-sec-Sec13" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Sec13" data-track="click" data-track-action="section anchor" data-track-label="link: Conclusions"><span class="c-article-section__title-number">5 </span>Conclusions</a></li><li id="rc-sec-notes" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#notes" data-track="click" data-track-action="section anchor" data-track-label="link: Notes"><span class="c-article-section__title-number"> </span>Notes</a></li><li id="rc-sec-Bib1" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Bib1" data-track="click" data-track-action="section anchor" data-track-label="link: References"><span class="c-article-section__title-number"> </span>References</a></li><li id="rc-sec-Ack1" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Ack1" data-track="click" data-track-action="section anchor" data-track-label="link: Acknowledgment"><span class="c-article-section__title-number"> </span>Acknowledgment</a></li><li id="rc-sec-author-information" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#author-information" data-track="click" data-track-action="section anchor" data-track-label="link: Author information"><span class="c-article-section__title-number"> </span>Author information</a></li><li id="rc-sec-editor-information" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#editor-information" data-track="click" data-track-action="section anchor" data-track-label="link: Editor information"><span class="c-article-section__title-number"> </span>Editor information</a></li><li id="rc-sec-rightslink" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#rightslink" data-track="click" data-track-action="section anchor" data-track-label="link: Rights and permissions"><span class="c-article-section__title-number"> </span>Rights and permissions</a></li><li id="rc-sec-copyright-information" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#copyright-information" data-track="click" data-track-action="section anchor" data-track-label="link: Copyright information"><span class="c-article-section__title-number"> </span>Copyright information</a></li><li id="rc-sec-chapter-info" class="c-reading-companion__section-item"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#chapter-info" data-track="click" data-track-action="section anchor" data-track-label="link: About this paper"><span class="c-article-section__title-number"> </span>About this paper</a></li></ul></div></div>
                    <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures" aria-labelledby="tab-figures" role="tabpanel"><div class="c-reading-companion__scroll-pane"><ul class="c-reading-companion__figures-list"><li class="c-reading-companion__figure-item"><figure><figcaption><b class="c-reading-companion__figure-title u-h4" id="rc-Fig1">Fig. 1.</b></figcaption><picture><source type="image/webp" data-srcset="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig1_HTML.gif?as=webp"><img data-src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig1_HTML.gif" alt="figure 1" aria-describedby="rc-Fig1"></picture><p class="c-reading-companion__figure-links"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig1" data-track="click" data-track-action="figure anchor" data-track-label="link">View in article</a><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/1" class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" rel="nofollow">Full size image<svg width="16" height="16" class="u-icon"><use href="#icon-chevron-right"></use></svg></a></p></figure></li><li class="c-reading-companion__figure-item"><figure><figcaption><b class="c-reading-companion__figure-title u-h4" id="rc-Fig2">Fig. 2.</b></figcaption><picture><source type="image/webp" data-srcset="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig2_HTML.gif?as=webp"><img data-src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig2_HTML.gif" alt="figure 2" aria-describedby="rc-Fig2"></picture><p class="c-reading-companion__figure-links"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig2" data-track="click" data-track-action="figure anchor" data-track-label="link">View in article</a><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/2" class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" rel="nofollow">Full size image<svg width="16" height="16" class="u-icon"><use href="#icon-chevron-right"></use></svg></a></p></figure></li><li class="c-reading-companion__figure-item"><figure><figcaption><b class="c-reading-companion__figure-title u-h4" id="rc-Fig3">Fig. 3.</b></figcaption><picture><source type="image/webp" data-srcset="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig3_HTML.gif?as=webp"><img data-src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig3_HTML.gif" alt="figure 3" aria-describedby="rc-Fig3"></picture><p class="c-reading-companion__figure-links"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig3" data-track="click" data-track-action="figure anchor" data-track-label="link">View in article</a><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/3" class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" rel="nofollow">Full size image<svg width="16" height="16" class="u-icon"><use href="#icon-chevron-right"></use></svg></a></p></figure></li><li class="c-reading-companion__figure-item"><figure><figcaption><b class="c-reading-companion__figure-title u-h4" id="rc-Fig4">Fig. 4.</b></figcaption><picture><source type="image/webp" data-srcset="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig4_HTML.gif?as=webp"><img data-src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig4_HTML.gif" alt="figure 4" aria-describedby="rc-Fig4"></picture><p class="c-reading-companion__figure-links"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig4" data-track="click" data-track-action="figure anchor" data-track-label="link">View in article</a><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/4" class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" rel="nofollow">Full size image<svg width="16" height="16" class="u-icon"><use href="#icon-chevron-right"></use></svg></a></p></figure></li><li class="c-reading-companion__figure-item"><figure><figcaption><b class="c-reading-companion__figure-title u-h4" id="rc-Fig5">Fig. 5.</b></figcaption><picture><source type="image/webp" data-srcset="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig5_HTML.gif?as=webp"><img data-src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-319-46448-0_2/MediaObjects/419956_1_En_2_Fig5_HTML.gif" alt="figure 5" aria-describedby="rc-Fig5"></picture><p class="c-reading-companion__figure-links"><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2#Fig5" data-track="click" data-track-action="figure anchor" data-track-label="link">View in article</a><a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2/figures/5" class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" rel="nofollow">Full size image<svg width="16" height="16" class="u-icon"><use href="#icon-chevron-right"></use></svg></a></p></figure></li></ul></div></div>
                    <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references" aria-labelledby="tab-references" role="tabpanel"><div class="c-reading-companion__scroll-pane"><ol class="c-reading-companion__references-list c-reading-companion__references-list--numeric"><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR1">Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W.: Selective search for object recognition. IJCV <b>104</b>, 154 (2013)</p><p class="c-reading-companion__reference-links"><a href="https://doi.org/10.1007%2Fs11263-013-0620-5" data-track="click" data-track-action="crossref reference" data-track-label="10.1007/s11263-013-0620-5">CrossRef</a>&nbsp;<a href="https://scholar.google.com/scholar_lookup?&amp;title=Selective%20search%20for%20object%20recognition&amp;journal=IJCV&amp;volume=104&amp;publication_year=2013&amp;author=Uijlings%2CJR&amp;author=Sande%2CKE&amp;author=Gevers%2CT&amp;author=Smeulders%2CAW" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                    Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR2">Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. In: NIPS (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Ren%2C%20S.%2C%20He%2C%20K.%2C%20Girshick%2C%20R.%2C%20Sun%2C%20J.%3A%20Faster%20R-CNN%3A%20towards%20real-time%20object%20detection%20with%20region%20proposal%20networks.%20In%3A%20NIPS%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR3">He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2016)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=He%2C%20K.%2C%20Zhang%2C%20X.%2C%20Ren%2C%20S.%2C%20Sun%2C%20J.%3A%20Deep%20residual%20learning%20for%20image%20recognition.%20In%3A%20CVPR%20%282016%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR4">Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: integrated recognition, localization and detection using convolutional networks. In: ICLR (2014)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Sermanet%2C%20P.%2C%20Eigen%2C%20D.%2C%20Zhang%2C%20X.%2C%20Mathieu%2C%20M.%2C%20Fergus%2C%20R.%2C%20LeCun%2C%20Y.%3A%20Overfeat%3A%20integrated%20recognition%2C%20localization%20and%20detection%20using%20convolutional%20networks.%20In%3A%20ICLR%20%282014%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR5">Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: CVPR (2016)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Redmon%2C%20J.%2C%20Divvala%2C%20S.%2C%20Girshick%2C%20R.%2C%20Farhadi%2C%20A.%3A%20You%20only%20look%20once%3A%20unified%2C%20real-time%20object%20detection.%20In%3A%20CVPR%20%282016%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR6">Girshick, R.: Fast R-CNN. In: ICCV (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Girshick%2C%20R.%3A%20Fast%20R-CNN.%20In%3A%20ICCV%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR7">Erhan, D., Szegedy, C., Toshev, A., Anguelov, D.: Scalable object detection using deep neural networks. In: CVPR (2014)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Erhan%2C%20D.%2C%20Szegedy%2C%20C.%2C%20Toshev%2C%20A.%2C%20Anguelov%2C%20D.%3A%20Scalable%20object%20detection%20using%20deep%20neural%20networks.%20In%3A%20CVPR%20%282014%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR8">Szegedy, C., Reed, S., Erhan, D., Anguelov, D.: Scalable, high-quality object detection. arXiv preprint v3 (2015). <a href="http://arxiv.org/abs/1412.1441">arXiv:1412.1441</a>
        </p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR9">He, K., Zhang, X., Ren, S., Sun, J.: Spatial pyramid pooling in deep convolutional networks for visual recognition. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.) ECCV 2014. LNCS, vol. 8691, pp. 346–361. Springer, Heidelberg (2014). doi:<a href="https://doi.org/10.1007/978-3-319-10578-9_23">10.1007/978-3-319-10578-9_23</a>
        </p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar_lookup?&amp;title=Spatial%20pyramid%20pooling%20in%20deep%20convolutional%20networks%20for%20visual%20recognition&amp;pages=346-361&amp;publication_year=2014&amp;author=He%2CK&amp;author=Zhang%2CX&amp;author=Ren%2CS&amp;author=Sun%2CJ" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                    Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR10">Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: CVPR (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Long%2C%20J.%2C%20Shelhamer%2C%20E.%2C%20Darrell%2C%20T.%3A%20Fully%20convolutional%20networks%20for%20semantic%20segmentation.%20In%3A%20CVPR%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR11">Hariharan, B., Arbeláez, P., Girshick, R., Malik, J.: Hypercolumns for object segmentation and fine-grained localization. In: CVPR (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Hariharan%2C%20B.%2C%20Arbel%C3%A1ez%2C%20P.%2C%20Girshick%2C%20R.%2C%20Malik%2C%20J.%3A%20Hypercolumns%20for%20object%20segmentation%20and%20fine-grained%20localization.%20In%3A%20CVPR%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR12">Liu, W., Rabinovich, A., Berg, A.C.: ParseNet: looking wider to see better. In: ILCR (2016)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Liu%2C%20W.%2C%20Rabinovich%2C%20A.%2C%20Berg%2C%20A.C.%3A%20ParseNet%3A%20looking%20wider%20to%20see%20better.%20In%3A%20ILCR%20%282016%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR13">Howard, A.G.: Some improvements on deep convolutional neural network based image classification. arXiv preprint (2013). <a href="http://arxiv.org/abs/1312.5402">arXiv:1312.5402</a>
        </p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR14">Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. In: NIPS (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Simonyan%2C%20K.%2C%20Zisserman%2C%20A.%3A%20Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition.%20In%3A%20NIPS%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR15">Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: Imagenet large scale visual recognition challenge. IJCV <b>115</b>, 211 (2015)</p><p class="c-reading-companion__reference-links"><a href="https://doi.org/10.1007%2Fs11263-015-0816-y" data-track="click" data-track-action="crossref reference" data-track-label="10.1007/s11263-015-0816-y">CrossRef</a>&nbsp;<a href="http://www.ams.org/mathscinet-getitem?mr=3422482" data-track="click" data-track-action="mathscinet reference" data-track-label="link">MathSciNet</a>&nbsp;<a href="https://scholar.google.com/scholar_lookup?&amp;title=Imagenet%20large%20scale%20visual%20recognition%20challenge&amp;journal=IJCV&amp;volume=115&amp;publication_year=2015&amp;author=Russakovsky%2CO&amp;author=Deng%2CJ&amp;author=Su%2CH&amp;author=Krause%2CJ&amp;author=Satheesh%2CS&amp;author=Ma%2CS&amp;author=Huang%2CZ&amp;author=Karpathy%2CA&amp;author=Khosla%2CA&amp;author=Bernstein%2CM&amp;author=Berg%2CAC&amp;author=Fei-Fei%2CL" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                    Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR16">Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Semantic image segmentation with deep convolutional nets and fully connected CRFs. In: ICLR (2015)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Chen%2C%20L.C.%2C%20Papandreou%2C%20G.%2C%20Kokkinos%2C%20I.%2C%20Murphy%2C%20K.%2C%20Yuille%2C%20A.L.%3A%20Semantic%20image%20segmentation%20with%20deep%20convolutional%20nets%20and%20fully%20connected%20CRFs.%20In%3A%20ICLR%20%282015%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR17">Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: convolutional architecture for fast feature embedding. In: MM. ACM (2014)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Jia%2C%20Y.%2C%20Shelhamer%2C%20E.%2C%20Donahue%2C%20J.%2C%20Karayev%2C%20S.%2C%20Long%2C%20J.%2C%20Girshick%2C%20R.%2C%20Guadarrama%2C%20S.%2C%20Darrell%2C%20T.%3A%20Caffe%3A%20convolutional%20architecture%20for%20fast%20feature%20embedding.%20In%3A%20MM.%20ACM%20%282014%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR18">Glorot, X., Bengio, Y.: Understanding the difficulty of training deep feedforward neural networks. In: AISTATS (2010)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Glorot%2C%20X.%2C%20Bengio%2C%20Y.%3A%20Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks.%20In%3A%20AISTATS%20%282010%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR19">Hoiem, D., Chodpathumwan, Y., Dai, Q.: Diagnosing error in object detectors. In: Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.) ECCV 2012. LNCS, vol. 7574, pp. 340–353. Springer, Heidelberg (2012). doi:<a href="https://doi.org/10.1007/978-3-642-33712-3_25">10.1007/978-3-642-33712-3_25</a>
        </p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar_lookup?&amp;title=Diagnosing%20error%20in%20object%20detectors&amp;pages=340-353&amp;publication_year=2012&amp;author=Hoiem%2CD&amp;author=Chodpathumwan%2CY&amp;author=Dai%2CQ" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                    Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR20">Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR (2014)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Girshick%2C%20R.%2C%20Donahue%2C%20J.%2C%20Darrell%2C%20T.%2C%20Malik%2C%20J.%3A%20Rich%20feature%20hierarchies%20for%20accurate%20object%20detection%20and%20semantic%20segmentation.%20In%3A%20CVPR%20%282014%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR21">Bell, S., Zitnick, C.L., Bala, K., Girshick, R.: Inside-outside net: detecting objects in context with skip pooling and recurrent neural networks. In: CVPR (2016)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Bell%2C%20S.%2C%20Zitnick%2C%20C.L.%2C%20Bala%2C%20K.%2C%20Girshick%2C%20R.%3A%20Inside-outside%20net%3A%20detecting%20objects%20in%20context%20with%20skip%20pooling%20and%20recurrent%20neural%20networks.%20In%3A%20CVPR%20%282016%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR22">COCO:Common Objects in Context (2016). <a href="http://mscoco.org/dataset/%23detections-leaderboard">http://mscoco.org/dataset/#detections-leaderboard</a>. Accessed 25 July 2016</p></li><li class="c-reading-companion__reference-item"><p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR23">Felzenszwalb, P., McAllester, D., Ramanan, D.: A discriminatively trained, multiscale, deformable part model. In: CVPR (2008)</p><p class="c-reading-companion__reference-links"><a href="https://scholar.google.com/scholar?&amp;q=Felzenszwalb%2C%20P.%2C%20McAllester%2C%20D.%2C%20Ramanan%2C%20D.%3A%20A%20discriminatively%20trained%2C%20multiscale%2C%20deformable%20part%20model.%20In%3A%20CVPR%20%282008%29" data-track="click" data-track-action="google scholar reference" data-track-label="link">
                        Google Scholar</a>&nbsp;</p></li></ol></div></div>
                </div>
            </div>
        </aside>
    </div>
</div>



        

        
    <footer class="app-footer" role="contentinfo" data-test="springerlink-footer">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic &amp; Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link" href="https://link.springer.com/siteEdition/link" id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link" href="https://link.springer.com/siteEdition/rd" id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="https://link.springer.com/">Home</a></li>
                <li><a href="https://link.springer.com/impressum">Impressum</a></li>
                <li><a href="https://link.springer.com/termsandconditions">Legal information</a></li>
                <li><a href="https://link.springer.com/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">Your US state privacy rights</a></li>
                <li><a href="https://link.springer.com/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" data-cc-action="preferences" href="javascript:void(0);">Your privacy choices/Manage cookies</a></li>
                
                <li><a href="https://link.springer.com/accessibility">Accessibility</a></li>
                <li><a href="https://support.springer.com/en/support/home">FAQ</a></li>
                <li><a id="contactus-footer-link" href="https://support.springer.com/en/support/solutions/articles/6000206179-contacting-us">Contact us</a></li>
                <li><a href="https://www.springer.com/gp/shop/promo/affiliate/springer-nature">Affiliate program</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 46.11.222.78</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="https://www.springernature.com/" title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo" src="/oscar-static/images/springerlink/png/springernature-60a72a849b.png" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="/oscar-static/images/springerlink/svg/springernature-b88bf25ad4.svg">
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">© 2023 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="https://www.springernature.com/">Springer Nature</a>.</p>
            
        </div>
    </footer>




    </div>

    <div class="u-visually-hidden" aria-hidden="true">
    
    <!--?xml version="1.0" encoding="UTF-8"?--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"></path></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"></path></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"></path></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"></path></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"></path></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"></path></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"></path></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"></path></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"></path></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"></path></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"></path></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"></path></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"></path></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"></path></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"></path></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"></path></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"></path></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"></path></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"></path></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"></path></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"></path></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"></path></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"></path></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"></path></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"></path></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"></path></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"></path></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"></path></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"></path></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"></path></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"></path></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"></path></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"></path></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"></path></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"></path></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"></path></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"></path></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"></path></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"></path></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"></path></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"></path></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"></path></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"></path></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"></path></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"></path></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"></path></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"></path></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"></path></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"></path></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"></path></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"></path></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"></path></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"></path></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"></path></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"></path></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"></path></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"></path></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill: none; --darkreader-inline-fill: none;" d="M0 0h56.69v56.69H0z" data-darkreader-inline-fill=""></path><clippath id="b"><use xlink:href="#a" style="overflow:visible"></use></clippath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path: url(&quot;#b&quot;); fill: none; stroke: rgb(1, 50, 75); stroke-width: 2; stroke-linecap: round; --darkreader-inline-fill: none; --darkreader-inline-stroke: #d0ccc6;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path: url(&quot;#b&quot;); fill: none; stroke: rgb(1, 50, 75); stroke-width: 2; stroke-linecap: round; stroke-linejoin: round; --darkreader-inline-fill: none; --darkreader-inline-stroke: #d0ccc6;" data-darkreader-inline-fill="" data-darkreader-inline-stroke=""></path></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"></path></symbol><symbol id="icon-eds-account" viewBox="0 0 24 24"><path fill-rule="nonzero" d="M12 12c5.498 0 10 4.001 10 9a1 1 0 0 1-2 0c0-3.838-3.557-7-8-7s-8 3.162-8 7a1 1 0 0 1-2 0c0-4.999 4.502-9 10-9Zm0-11a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm0 2a3 3 0 1 1 0 6 3 3 0 0 1 0-6Z"></path></symbol><symbol id="icon-eds-search" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z" fill-rule="nonzero"></path></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"></path></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></symbol><symbol id="icon-menu" viewBox="0 0 24 24"><path d="M21.09 5c.503 0 .91.448.91 1s-.407 1-.91 1H2.91C2.406 7 2 6.552 2 6s.407-1 .91-1h18.18Zm-3.817 6c.401 0 .727.448.727 1s-.326 1-.727 1H2.727C2.326 13 2 12.552 2 12s.326-1 .727-1h14.546Zm3.818 6c.502 0 .909.448.909 1s-.407 1-.91 1H2.91c-.503 0-.91-.448-.91-1s.407-1 .91-1h18.18Z" fill-rule="nonzero"></path></symbol><symbol id="icon-search-filter" viewBox="0 0 29 29"><path d="M28 9H11a1 1 0 0 1 0-2h17a1 1 0 0 1 0 2ZM7 9H4a1 1 0 0 1 0-2h3a1 1 0 0 1 0 2Zm14 8H4a1 1 0 0 1 0-2h17a1 1 0 0 1 0 2Zm-10 8H4a1 1 0 0 1 0-2h7a1 1 0 0 1 0 2Z"></path><path d="M9 11a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1Zm14 12a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1ZM13 27a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1Z"></path><path d="M28 17h-3a1 1 0 0 1 0-2h3a1 1 0 0 1 0 2Zm0 8H15a1 1 0 0 1 0-2h13a1 1 0 0 1 0 2Z"></path><path d="M0 0h32v32H0z" style="fill: none; --darkreader-inline-fill: none;" data-darkreader-inline-fill=""></path></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"></path></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"></path></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"></path></symbol></svg>
</div>

<script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/app-es5-bundle-c8d17b980a.js.download" nomodule="true"></script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/app-es6-bundle-1a36c45380.js.download" type="module"></script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/global-article-es5-bundle-f999617c9b.js.download" nomodule="true"></script><script src="./SSD_ Single Shot MultiBox Detector _ SpringerLink_files/global-article-es6-bundle-1051dda857.js.download" type="module"></script><div data-cc-ghost="" style="height: 351px;"></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px; --darkreader-inline-border-top: initial; --darkreader-inline-border-right: initial; --darkreader-inline-border-bottom: initial; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left=""><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_AMS, monospace; --darkreader-inline-border-top: initial; --darkreader-inline-border-right: initial; --darkreader-inline-border-bottom: initial; --darkreader-inline-border-left: initial;" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left=""></div></div></body></html>